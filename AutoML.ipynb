{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9zc94v8F3lf",
        "outputId": "735f364e-be90-4531-db14-355b8b6c8840"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining tods from git+https://github.com/datamllab/tods.git#egg=tods\n",
            "  Updating ./src/tods clone\n",
            "  Running command git fetch -q --tags\n",
            "  Running command git reset --hard -q d0a5f9d87f6b3cf57b849d8fb8481905b5930bd4\n",
            "Requirement already satisfied: tamu_d3m==2022.05.23 in /usr/local/lib/python3.7/dist-packages (from tods) (2022.5.23)\n",
            "Requirement already satisfied: tamu_axolotl in /usr/local/lib/python3.7/dist-packages (from tods) (2021.4.8)\n",
            "Requirement already satisfied: numpy<=1.21.2 in /usr/local/lib/python3.7/dist-packages (from tods) (1.19.5)\n",
            "Requirement already satisfied: combo in /usr/local/lib/python3.7/dist-packages (from tods) (0.1.3)\n",
            "Requirement already satisfied: simplejson==3.12.0 in /usr/local/lib/python3.7/dist-packages (from tods) (3.12.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from tods) (0.24.2)\n",
            "Requirement already satisfied: statsmodels==0.11.1 in /usr/local/lib/python3.7/dist-packages (from tods) (0.11.1)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tods) (1.3.0)\n",
            "Requirement already satisfied: pillow==7.1.2 in /usr/local/lib/python3.7/dist-packages (from tods) (7.1.2)\n",
            "Requirement already satisfied: tensorflow==2.4 in /usr/local/lib/python3.7/dist-packages (from tods) (2.4.0)\n",
            "Requirement already satisfied: keras==2.4.0 in /usr/local/lib/python3.7/dist-packages (from tods) (2.4.0)\n",
            "Requirement already satisfied: pyod in /usr/local/lib/python3.7/dist-packages (from tods) (1.0.2)\n",
            "Requirement already satisfied: nimfa==1.4.0 in /usr/local/lib/python3.7/dist-packages (from tods) (1.4.0)\n",
            "Requirement already satisfied: stumpy==1.4.0 in /usr/local/lib/python3.7/dist-packages (from tods) (1.4.0)\n",
            "Requirement already satisfied: more-itertools==8.5.0 in /usr/local/lib/python3.7/dist-packages (from tods) (8.5.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.4.0->tods) (5.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras==2.4.0->tods) (2.10.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.4.0->tods) (1.7.1)\n",
            "Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.7/dist-packages (from statsmodels==0.11.1->tods) (0.5.2)\n",
            "Requirement already satisfied: pandas>=0.21 in /usr/local/lib/python3.7/dist-packages (from statsmodels==0.11.1->tods) (1.3.4)\n",
            "Requirement already satisfied: numba>=0.42.0 in /usr/local/lib/python3.7/dist-packages (from stumpy==1.4.0->tods) (0.51.2)\n",
            "Requirement already satisfied: jsonschema<=4.0.1,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from tamu_d3m==2022.05.23->tods) (4.0.1)\n",
            "Requirement already satisfied: rfc3986-validator<0.2,>=0.1 in /usr/local/lib/python3.7/dist-packages (from tamu_d3m==2022.05.23->tods) (0.1.1)\n",
            "Requirement already satisfied: python-dateutil<=2.8.2,>=2.8.1 in /usr/local/lib/python3.7/dist-packages (from tamu_d3m==2022.05.23->tods) (2.8.2)\n",
            "Requirement already satisfied: dateparser<1.2.0,>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tamu_d3m==2022.05.23->tods) (1.1.1)\n",
            "Requirement already satisfied: frozendict==1.2 in /usr/local/lib/python3.7/dist-packages (from tamu_d3m==2022.05.23->tods) (1.2)\n",
            "Requirement already satisfied: pyrsistent<=0.18.0,>=0.14.11 in /usr/local/lib/python3.7/dist-packages (from tamu_d3m==2022.05.23->tods) (0.18.0)\n",
            "Requirement already satisfied: custom-inherit<=2.3.2,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from tamu_d3m==2022.05.23->tods) (2.3.2)\n",
            "Requirement already satisfied: webcolors<=1.11.1,>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from tamu_d3m==2022.05.23->tods) (1.11.1)\n",
            "Requirement already satisfied: pytypes>=1.0b5 in /usr/local/lib/python3.7/dist-packages (from tamu_d3m==2022.05.23->tods) (1.0b10)\n",
            "Requirement already satisfied: jsonpath-ng<=1.5.3,>=1.4.3 in /usr/local/lib/python3.7/dist-packages (from tamu_d3m==2022.05.23->tods) (1.5.3)\n",
            "Requirement already satisfied: GitPython<=3.1.24,>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tamu_d3m==2022.05.23->tods) (3.1.24)\n",
            "Requirement already satisfied: rfc3339-validator<0.2,>=0.1 in /usr/local/lib/python3.7/dist-packages (from tamu_d3m==2022.05.23->tods) (0.1.4)\n",
            "Requirement already satisfied: typing-inspect==0.7.1 in /usr/local/lib/python3.7/dist-packages (from tamu_d3m==2022.05.23->tods) (0.7.1)\n",
            "Requirement already satisfied: gputil<=1.4.0,>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from tamu_d3m==2022.05.23->tods) (1.4.0)\n",
            "Requirement already satisfied: requests<=2.26.0,>=2.19.1 in /usr/local/lib/python3.7/dist-packages (from tamu_d3m==2022.05.23->tods) (2.23.0)\n",
            "Requirement already satisfied: openml==0.11.0 in /usr/local/lib/python3.7/dist-packages (from tamu_d3m==2022.05.23->tods) (0.11.0)\n",
            "Requirement already satisfied: liac-arff>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from openml==0.11.0->tamu_d3m==2022.05.23->tods) (2.5.0)\n",
            "Requirement already satisfied: xmltodict in /usr/local/lib/python3.7/dist-packages (from openml==0.11.0->tamu_d3m==2022.05.23->tods) (0.13.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4->tods) (1.6.3)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4->tods) (1.32.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4->tods) (2.4.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4->tods) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4->tods) (3.17.3)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4->tods) (1.1.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4->tods) (0.37.1)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4->tods) (1.15.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4->tods) (1.12.1)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4->tods) (2.8.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4->tods) (0.15.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4->tods) (3.7.4.3)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4->tods) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4->tods) (1.1.2)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4->tods) (0.3.3)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4->tods) (1.12)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from typing-inspect==0.7.1->tamu_d3m==2022.05.23->tods) (0.4.3)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.7/dist-packages (from dateparser<1.2.0,>=0.7.0->tamu_d3m==2022.05.23->tods) (1.5.1)\n",
            "Requirement already satisfied: regex!=2019.02.19,!=2021.8.27,<2022.3.15 in /usr/local/lib/python3.7/dist-packages (from dateparser<1.2.0,>=0.7.0->tamu_d3m==2022.05.23->tods) (2022.3.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from dateparser<1.2.0,>=0.7.0->tamu_d3m==2022.05.23->tods) (2022.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython<=3.1.24,>=3.1.0->tamu_d3m==2022.05.23->tods) (4.0.9)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython<=3.1.24,>=3.1.0->tamu_d3m==2022.05.23->tods) (5.0.0)\n",
            "Requirement already satisfied: ply in /usr/local/lib/python3.7/dist-packages (from jsonpath-ng<=1.5.3,>=1.4.3->tamu_d3m==2022.05.23->tods) (3.11)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from jsonpath-ng<=1.5.3,>=1.4.3->tamu_d3m==2022.05.23->tods) (4.4.2)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema<=4.0.1,>=3.0.2->tamu_d3m==2022.05.23->tods) (21.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema<=4.0.1,>=3.0.2->tamu_d3m==2022.05.23->tods) (4.11.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.42.0->stumpy==1.4.0->tods) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.42.0->stumpy==1.4.0->tods) (0.34.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<=2.26.0,>=2.19.1->tamu_d3m==2022.05.23->tods) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<=2.26.0,>=2.19.1->tamu_d3m==2022.05.23->tods) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<=2.26.0,>=2.19.1->tamu_d3m==2022.05.23->tods) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<=2.26.0,>=2.19.1->tamu_d3m==2022.05.23->tods) (2.10)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->tods) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->tods) (1.1.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4->tods) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4->tods) (3.3.7)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4->tods) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4->tods) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4->tods) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4->tods) (1.35.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4->tods) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4->tods) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4->tods) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4->tods) (1.3.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->jsonschema<=4.0.1,>=3.0.2->tamu_d3m==2022.05.23->tods) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4->tods) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4->tods) (3.2.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from combo->tods) (3.2.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->combo->tods) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->combo->tods) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->combo->tods) (1.4.3)\n",
            "Requirement already satisfied: grpcio-testing in /usr/local/lib/python3.7/dist-packages (from tamu_axolotl->tods) (1.32.0)\n",
            "Requirement already satisfied: ray<=1.0.1.post1 in /usr/local/lib/python3.7/dist-packages (from tamu_axolotl->tods) (1.0.1.post1)\n",
            "Requirement already satisfied: networkx==2.4 in /usr/local/lib/python3.7/dist-packages (from tamu_axolotl->tods) (2.4)\n",
            "Requirement already satisfied: grpcio-tools in /usr/local/lib/python3.7/dist-packages (from tamu_axolotl->tods) (1.32.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from ray<=1.0.1.post1->tamu_axolotl->tods) (0.4.5)\n",
            "Requirement already satisfied: google in /usr/local/lib/python3.7/dist-packages (from ray<=1.0.1.post1->tamu_axolotl->tods) (2.0.3)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray<=1.0.1.post1->tamu_axolotl->tods) (1.0.4)\n",
            "Requirement already satisfied: py-spy>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ray<=1.0.1.post1->tamu_axolotl->tods) (0.3.12)\n",
            "Requirement already satisfied: aioredis in /usr/local/lib/python3.7/dist-packages (from ray<=1.0.1.post1->tamu_axolotl->tods) (2.0.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray<=1.0.1.post1->tamu_axolotl->tods) (7.1.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from ray<=1.0.1.post1->tamu_axolotl->tods) (3.8.1)\n",
            "Requirement already satisfied: aiohttp-cors in /usr/local/lib/python3.7/dist-packages (from ray<=1.0.1.post1->tamu_axolotl->tods) (0.7.0)\n",
            "Requirement already satisfied: colorful in /usr/local/lib/python3.7/dist-packages (from ray<=1.0.1.post1->tamu_axolotl->tods) (0.5.4)\n",
            "Requirement already satisfied: opencensus in /usr/local/lib/python3.7/dist-packages (from ray<=1.0.1.post1->tamu_axolotl->tods) (0.9.0)\n",
            "Requirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from ray<=1.0.1.post1->tamu_axolotl->tods) (0.14.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray<=1.0.1.post1->tamu_axolotl->tods) (3.7.1)\n",
            "Requirement already satisfied: redis<3.5.0,>=3.3.2 in /usr/local/lib/python3.7/dist-packages (from ray<=1.0.1.post1->tamu_axolotl->tods) (3.4.1)\n",
            "Requirement already satisfied: gpustat in /usr/local/lib/python3.7/dist-packages (from ray<=1.0.1.post1->tamu_axolotl->tods) (0.6.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->ray<=1.0.1.post1->tamu_axolotl->tods) (1.7.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->ray<=1.0.1.post1->tamu_axolotl->tods) (4.0.2)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->ray<=1.0.1.post1->tamu_axolotl->tods) (0.13.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->ray<=1.0.1.post1->tamu_axolotl->tods) (1.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->ray<=1.0.1.post1->tamu_axolotl->tods) (1.3.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->ray<=1.0.1.post1->tamu_axolotl->tods) (6.0.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->ray<=1.0.1.post1->tamu_axolotl->tods) (2.0.12)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from google->ray<=1.0.1.post1->tamu_axolotl->tods) (4.6.3)\n",
            "Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.7/dist-packages (from gpustat->ray<=1.0.1.post1->tamu_axolotl->tods) (7.352.0)\n",
            "Requirement already satisfied: blessings>=1.6 in /usr/local/lib/python3.7/dist-packages (from gpustat->ray<=1.0.1.post1->tamu_axolotl->tods) (1.7)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from gpustat->ray<=1.0.1.post1->tamu_axolotl->tods) (5.4.8)\n",
            "Requirement already satisfied: opencensus-context>=0.1.2 in /usr/local/lib/python3.7/dist-packages (from opencensus->ray<=1.0.1.post1->tamu_axolotl->tods) (0.1.2)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from opencensus->ray<=1.0.1.post1->tamu_axolotl->tods) (1.31.6)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray<=1.0.1.post1->tamu_axolotl->tods) (21.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray<=1.0.1.post1->tamu_axolotl->tods) (1.56.2)\n",
            "Installing collected packages: tods\n",
            "  Attempting uninstall: tods\n",
            "    Found existing installation: tods 0.0.2\n",
            "    Can't uninstall 'tods'. No files were found to uninstall.\n",
            "  Running setup.py develop for tods\n",
            "Successfully installed tods-0.0.2\n"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "!pip install -e git+https://github.com/datamllab/tods.git#egg=tods \n",
        "exit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QxnL8Uw_G-6L"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import argparse\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import metrics\n",
        "from d3m import index\n",
        "from d3m.metadata.base import ArgumentType\n",
        "from d3m.metadata.pipeline import Pipeline, PrimitiveStep\n",
        "from axolotl.backend.simple import SimpleRunner\n",
        "from tods import generate_dataset, generate_problem\n",
        "from tods.searcher import BruteForceSearch\n",
        "from tods import generate_dataset, load_pipeline, evaluate_pipeline\n",
        "from tods.sk_interface.detection_algorithm.DeepLog_skinterface import DeepLogSKI\n",
        "from tods.sk_interface.detection_algorithm.Telemanom_skinterface import TelemanomSKI\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bT6miDKO6b8",
        "outputId": "e03245af-0074-4798-e4c7-7f1aadd3b7c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GPQTjrB1IrlF"
      },
      "outputs": [],
      "source": [
        "# Load TRAIN / TEST data from drive\n",
        "#labelDF = pd.read_csv('/content/drive/MyDrive/all_flights_detail_label2.csv', header=None)\n",
        "labelDF = pd.read_csv('/content/drive/MyDrive/speed_t4013.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#labelDF=labelDF.iloc[:,0:2]\n",
        "labelDF['timestamp'] = pd.to_datetime(labelDF['timestamp'])\n",
        "labelDF['timestamp'] = (labelDF['timestamp'] - pd.Timestamp(\"1970-01-01\")) // pd.Timedelta('1s')"
      ],
      "metadata": {
        "id": "YGxF7AYbcLX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xDx6fbJVRUR8"
      },
      "outputs": [],
      "source": [
        "labelDF = labelDF.drop(labelDF.columns[[5, 6, 7]], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "EQ5ifgc4Rp2P",
        "outputId": "27d40c05-3a81-4986-e002-a9fe0cda0ce5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       timestamp  value  label\n",
              "2490  1442505540     61      0\n",
              "2491  1442505840     66      0\n",
              "2492  1442506140     65      0\n",
              "2493  1442506440     65      0\n",
              "2494  1442506740     60      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f39286a4-0b5f-475d-bcb5-9e95dba2d871\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timestamp</th>\n",
              "      <th>value</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2490</th>\n",
              "      <td>1442505540</td>\n",
              "      <td>61</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2491</th>\n",
              "      <td>1442505840</td>\n",
              "      <td>66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2492</th>\n",
              "      <td>1442506140</td>\n",
              "      <td>65</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2493</th>\n",
              "      <td>1442506440</td>\n",
              "      <td>65</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2494</th>\n",
              "      <td>1442506740</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f39286a4-0b5f-475d-bcb5-9e95dba2d871')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f39286a4-0b5f-475d-bcb5-9e95dba2d871 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f39286a4-0b5f-475d-bcb5-9e95dba2d871');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "labelDF.tail()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "group1 = new_labels[new_labels[0] == 0]\n",
        "group1 = group1.iloc[:,0:3]\n",
        "group2 = new_labels[new_labels[0] == 1]\n",
        "group2 = group2.iloc[:,0:3]\n",
        "#group3 = new_labels[new_labels[0] == 2]\n",
        "#group3 = group3.iloc[:,0:3]"
      ],
      "metadata": {
        "id": "LKmf06Dwmx0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "group1.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "UnXIowFDnmEC",
        "outputId": "d2b1ae26-b3dc-4122-c2a4-a3944b503cfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    timestamp  value  label\n",
              "0  1441106700     58      0\n",
              "1  1441107000     63      0\n",
              "2  1441107300     63      0\n",
              "3  1441107600     64      0\n",
              "4  1441108500     58      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ef0e9697-81eb-4249-90b4-b536221265eb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timestamp</th>\n",
              "      <th>value</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1441106700</td>\n",
              "      <td>58</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1441107000</td>\n",
              "      <td>63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1441107300</td>\n",
              "      <td>63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1441107600</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1441108500</td>\n",
              "      <td>58</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ef0e9697-81eb-4249-90b4-b536221265eb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ef0e9697-81eb-4249-90b4-b536221265eb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ef0e9697-81eb-4249-90b4-b536221265eb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PkvoirehAyRy"
      },
      "outputs": [],
      "source": [
        "group1=labelDF.iloc[0:1999]\n",
        "group2=labelDF.iloc[2000:3999]\n",
        "group3=labelDF.iloc[4000:5999]\n",
        "group4=labelDF.iloc[6000:7999]\n",
        "group5=labelDF.iloc[8000:9999]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44dYOnlXPAai"
      },
      "outputs": [],
      "source": [
        "group2.reset_index(drop=True, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0l_HerhlR6tc",
        "outputId": "0f4a22cf-0cba-4f1c-cdd7-c405192c39f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Not all provided hyper-parameters for the data preparation pipeline 79ce71bd-db96-494b-a455-14f2e2ac5040 were used: ['method', 'number_of_folds', 'randomSeed', 'shuffle', 'stratified']\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
            "  warnings.warn(\"Numerical issues were encountered \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_27\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_382 (Dense)            (None, 4)                 20        \n",
            "_________________________________________________________________\n",
            "dropout_255 (Dropout)        (None, 4)                 0         \n",
            "_________________________________________________________________\n",
            "dense_383 (Dense)            (None, 4)                 20        \n",
            "_________________________________________________________________\n",
            "dropout_256 (Dropout)        (None, 4)                 0         \n",
            "_________________________________________________________________\n",
            "dense_384 (Dense)            (None, 1)                 5         \n",
            "_________________________________________________________________\n",
            "dropout_257 (Dropout)        (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "dense_385 (Dense)            (None, 4)                 8         \n",
            "_________________________________________________________________\n",
            "dropout_258 (Dropout)        (None, 4)                 0         \n",
            "_________________________________________________________________\n",
            "dense_386 (Dense)            (None, 1)                 5         \n",
            "_________________________________________________________________\n",
            "dropout_259 (Dropout)        (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "dense_387 (Dense)            (None, 4)                 8         \n",
            "=================================================================\n",
            "Total params: 66\n",
            "Trainable params: 66\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 1668 samples, validate on 186 samples\n",
            "Epoch 1/20\n",
            "1568/1668 [===========================>..] - ETA: 0s - loss: 1.5293"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1668/1668 [==============================] - 7s 4ms/sample - loss: 1.5104 - val_loss: 1.3168\n",
            "Epoch 2/20\n",
            "1668/1668 [==============================] - 0s 109us/sample - loss: 1.4214 - val_loss: 1.2627\n",
            "Epoch 3/20\n",
            "1668/1668 [==============================] - 0s 108us/sample - loss: 1.3581 - val_loss: 1.2137\n",
            "Epoch 4/20\n",
            "1668/1668 [==============================] - 0s 113us/sample - loss: 1.3063 - val_loss: 1.1679\n",
            "Epoch 5/20\n",
            "1668/1668 [==============================] - 0s 115us/sample - loss: 1.2544 - val_loss: 1.1227\n",
            "Epoch 6/20\n",
            "1668/1668 [==============================] - 0s 114us/sample - loss: 1.2048 - val_loss: 1.0764\n",
            "Epoch 7/20\n",
            "1668/1668 [==============================] - 0s 117us/sample - loss: 1.1611 - val_loss: 1.0389\n",
            "Epoch 8/20\n",
            "1668/1668 [==============================] - 0s 116us/sample - loss: 1.1241 - val_loss: 1.0072\n",
            "Epoch 9/20\n",
            "1668/1668 [==============================] - 0s 113us/sample - loss: 1.0924 - val_loss: 0.9806\n",
            "Epoch 10/20\n",
            "1668/1668 [==============================] - 0s 117us/sample - loss: 1.0693 - val_loss: 0.9577\n",
            "Epoch 11/20\n",
            "1668/1668 [==============================] - 0s 109us/sample - loss: 1.0459 - val_loss: 0.9380\n",
            "Epoch 12/20\n",
            "1668/1668 [==============================] - 0s 113us/sample - loss: 1.0255 - val_loss: 0.9204\n",
            "Epoch 13/20\n",
            "1668/1668 [==============================] - 0s 107us/sample - loss: 1.0052 - val_loss: 0.9052\n",
            "Epoch 14/20\n",
            "1668/1668 [==============================] - 0s 107us/sample - loss: 0.9882 - val_loss: 0.8915\n",
            "Epoch 15/20\n",
            "1668/1668 [==============================] - 0s 109us/sample - loss: 0.9796 - val_loss: 0.8799\n",
            "Epoch 16/20\n",
            "1668/1668 [==============================] - 0s 110us/sample - loss: 0.9707 - val_loss: 0.8697\n",
            "Epoch 17/20\n",
            "1668/1668 [==============================] - 0s 108us/sample - loss: 0.9572 - val_loss: 0.8603\n",
            "Epoch 18/20\n",
            "1668/1668 [==============================] - 0s 109us/sample - loss: 0.9523 - val_loss: 0.8520\n",
            "Epoch 19/20\n",
            "1668/1668 [==============================] - 0s 109us/sample - loss: 0.9439 - val_loss: 0.8444\n",
            "Epoch 20/20\n",
            "1668/1668 [==============================] - 0s 109us/sample - loss: 0.9340 - val_loss: 0.8373\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
            "  warnings.warn(\"Numerical issues were encountered \"\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/src/tods/tods/searcher/brute_force_search.py\", line 62, in _search\n",
            "    for error in pipeline_result.error:\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "Not all provided hyper-parameters for the data preparation pipeline 79ce71bd-db96-494b-a455-14f2e2ac5040 were used: ['method', 'number_of_folds', 'randomSeed', 'shuffle', 'stratified']\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
            "  warnings.warn(\"Numerical issues were encountered \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_28\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_388 (Dense)            (None, 4)                 20        \n",
            "_________________________________________________________________\n",
            "dropout_260 (Dropout)        (None, 4)                 0         \n",
            "_________________________________________________________________\n",
            "dense_389 (Dense)            (None, 4)                 20        \n",
            "_________________________________________________________________\n",
            "dropout_261 (Dropout)        (None, 4)                 0         \n",
            "_________________________________________________________________\n",
            "dense_390 (Dense)            (None, 1)                 5         \n",
            "_________________________________________________________________\n",
            "dropout_262 (Dropout)        (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "dense_391 (Dense)            (None, 4)                 8         \n",
            "_________________________________________________________________\n",
            "dropout_263 (Dropout)        (None, 4)                 0         \n",
            "_________________________________________________________________\n",
            "dense_392 (Dense)            (None, 1)                 5         \n",
            "_________________________________________________________________\n",
            "dropout_264 (Dropout)        (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "dense_393 (Dense)            (None, 4)                 8         \n",
            "=================================================================\n",
            "Total params: 66\n",
            "Trainable params: 66\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 1668 samples, validate on 186 samples\n",
            "Epoch 1/20\n",
            "1632/1668 [============================>.] - ETA: 0s - loss: 1.4148"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1668/1668 [==============================] - 7s 4ms/sample - loss: 1.4302 - val_loss: 1.3626\n",
            "Epoch 2/20\n",
            "1668/1668 [==============================] - 0s 107us/sample - loss: 1.3473 - val_loss: 1.2915\n",
            "Epoch 3/20\n",
            "1668/1668 [==============================] - 0s 106us/sample - loss: 1.2761 - val_loss: 1.2314\n",
            "Epoch 4/20\n",
            "1668/1668 [==============================] - 0s 106us/sample - loss: 1.2264 - val_loss: 1.1829\n",
            "Epoch 5/20\n",
            "1668/1668 [==============================] - 0s 107us/sample - loss: 1.1860 - val_loss: 1.1415\n",
            "Epoch 6/20\n",
            "1668/1668 [==============================] - 0s 109us/sample - loss: 1.1437 - val_loss: 1.1072\n",
            "Epoch 7/20\n",
            "1668/1668 [==============================] - 0s 108us/sample - loss: 1.1105 - val_loss: 1.0781\n",
            "Epoch 8/20\n",
            "1668/1668 [==============================] - 0s 109us/sample - loss: 1.0801 - val_loss: 1.0512\n",
            "Epoch 9/20\n",
            "1668/1668 [==============================] - 0s 108us/sample - loss: 1.0628 - val_loss: 1.0292\n",
            "Epoch 10/20\n",
            "1668/1668 [==============================] - 0s 111us/sample - loss: 1.0356 - val_loss: 1.0103\n",
            "Epoch 11/20\n",
            "1668/1668 [==============================] - 0s 110us/sample - loss: 1.0200 - val_loss: 0.9936\n",
            "Epoch 12/20\n",
            "1668/1668 [==============================] - 0s 106us/sample - loss: 1.0056 - val_loss: 0.9785\n",
            "Epoch 13/20\n",
            "1668/1668 [==============================] - 0s 109us/sample - loss: 0.9954 - val_loss: 0.9653\n",
            "Epoch 14/20\n",
            "1668/1668 [==============================] - 0s 110us/sample - loss: 0.9834 - val_loss: 0.9536\n",
            "Epoch 15/20\n",
            "1668/1668 [==============================] - 0s 108us/sample - loss: 0.9716 - val_loss: 0.9429\n",
            "Epoch 16/20\n",
            "1668/1668 [==============================] - 0s 107us/sample - loss: 0.9577 - val_loss: 0.9329\n",
            "Epoch 17/20\n",
            "1668/1668 [==============================] - 0s 111us/sample - loss: 0.9479 - val_loss: 0.9239\n",
            "Epoch 18/20\n",
            "1668/1668 [==============================] - 0s 111us/sample - loss: 0.9367 - val_loss: 0.9156\n",
            "Epoch 19/20\n",
            "1668/1668 [==============================] - 0s 108us/sample - loss: 0.9302 - val_loss: 0.9081\n",
            "Epoch 20/20\n",
            "1668/1668 [==============================] - 0s 109us/sample - loss: 0.9260 - val_loss: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
            "  warnings.warn(\"Numerical issues were encountered \"\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/src/tods/tods/searcher/brute_force_search.py\", line 62, in _search\n",
            "    for error in pipeline_result.error:\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "Not all provided hyper-parameters for the data preparation pipeline 79ce71bd-db96-494b-a455-14f2e2ac5040 were used: ['method', 'number_of_folds', 'randomSeed', 'shuffle', 'stratified']\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
            "  warnings.warn(\"Numerical issues were encountered \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_29\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_394 (Dense)            (None, 4)                 20        \n",
            "_________________________________________________________________\n",
            "dropout_265 (Dropout)        (None, 4)                 0         \n",
            "_________________________________________________________________\n",
            "dense_395 (Dense)            (None, 4)                 20        \n",
            "_________________________________________________________________\n",
            "dropout_266 (Dropout)        (None, 4)                 0         \n",
            "_________________________________________________________________\n",
            "dense_396 (Dense)            (None, 1)                 5         \n",
            "_________________________________________________________________\n",
            "dropout_267 (Dropout)        (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "dense_397 (Dense)            (None, 4)                 8         \n",
            "_________________________________________________________________\n",
            "dropout_268 (Dropout)        (None, 4)                 0         \n",
            "_________________________________________________________________\n",
            "dense_398 (Dense)            (None, 1)                 5         \n",
            "_________________________________________________________________\n",
            "dropout_269 (Dropout)        (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "dense_399 (Dense)            (None, 4)                 8         \n",
            "=================================================================\n",
            "Total params: 66\n",
            "Trainable params: 66\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 1668 samples, validate on 186 samples\n",
            "Epoch 1/20\n",
            "1600/1668 [===========================>..] - ETA: 0s - loss: 1.6196"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1668/1668 [==============================] - 7s 4ms/sample - loss: 1.6114 - val_loss: 1.3776\n",
            "Epoch 2/20\n",
            "1668/1668 [==============================] - 0s 108us/sample - loss: 1.4847 - val_loss: 1.2840\n",
            "Epoch 3/20\n",
            "1668/1668 [==============================] - 0s 107us/sample - loss: 1.3915 - val_loss: 1.2094\n",
            "Epoch 4/20\n",
            "1668/1668 [==============================] - 0s 107us/sample - loss: 1.3185 - val_loss: 1.1481\n",
            "Epoch 5/20\n",
            "1668/1668 [==============================] - 0s 108us/sample - loss: 1.2593 - val_loss: 1.0997\n",
            "Epoch 6/20\n",
            "1668/1668 [==============================] - 0s 107us/sample - loss: 1.2122 - val_loss: 1.0601\n",
            "Epoch 7/20\n",
            "1668/1668 [==============================] - 0s 106us/sample - loss: 1.1730 - val_loss: 1.0255\n",
            "Epoch 8/20\n",
            "1668/1668 [==============================] - 0s 103us/sample - loss: 1.1389 - val_loss: 0.9956\n",
            "Epoch 9/20\n",
            "1668/1668 [==============================] - 0s 108us/sample - loss: 1.1084 - val_loss: 0.9704\n",
            "Epoch 10/20\n",
            "1668/1668 [==============================] - 0s 109us/sample - loss: 1.0850 - val_loss: 0.9484\n",
            "Epoch 11/20\n",
            "1668/1668 [==============================] - 0s 109us/sample - loss: 1.0606 - val_loss: 0.9277\n",
            "Epoch 12/20\n",
            "1668/1668 [==============================] - 0s 106us/sample - loss: 1.0422 - val_loss: 0.9107\n",
            "Epoch 13/20\n",
            "1668/1668 [==============================] - 0s 104us/sample - loss: 1.0238 - val_loss: 0.8958\n",
            "Epoch 14/20\n",
            "1668/1668 [==============================] - 0s 107us/sample - loss: 1.0097 - val_loss: 0.8826\n",
            "Epoch 15/20\n",
            "1668/1668 [==============================] - 0s 108us/sample - loss: 0.9950 - val_loss: 0.8706\n",
            "Epoch 16/20\n",
            "1668/1668 [==============================] - 0s 109us/sample - loss: 0.9802 - val_loss: 0.8598\n",
            "Epoch 17/20\n",
            "1668/1668 [==============================] - 0s 108us/sample - loss: 0.9688 - val_loss: 0.8501\n",
            "Epoch 18/20\n",
            "1668/1668 [==============================] - 0s 104us/sample - loss: 0.9632 - val_loss: 0.8419\n",
            "Epoch 19/20\n",
            "1668/1668 [==============================] - 0s 106us/sample - loss: 0.9445 - val_loss: 0.8339\n",
            "Epoch 20/20\n",
            "1668/1668 [==============================] - 0s 107us/sample - loss: 0.9419 - val_loss: 0.8269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
            "  warnings.warn(\"Numerical issues were encountered \"\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/src/tods/tods/searcher/brute_force_search.py\", line 62, in _search\n",
            "    for error in pipeline_result.error:\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "Not all provided hyper-parameters for the data preparation pipeline 79ce71bd-db96-494b-a455-14f2e2ac5040 were used: ['method', 'number_of_folds', 'randomSeed', 'shuffle', 'stratified']\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
            "  warnings.warn(\"Numerical issues were encountered \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_30\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_400 (Dense)            (None, 4)                 20        \n",
            "_________________________________________________________________\n",
            "dropout_270 (Dropout)        (None, 4)                 0         \n",
            "_________________________________________________________________\n",
            "dense_401 (Dense)            (None, 4)                 20        \n",
            "_________________________________________________________________\n",
            "dropout_271 (Dropout)        (None, 4)                 0         \n",
            "_________________________________________________________________\n",
            "dense_402 (Dense)            (None, 1)                 5         \n",
            "_________________________________________________________________\n",
            "dropout_272 (Dropout)        (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "dense_403 (Dense)            (None, 4)                 8         \n",
            "_________________________________________________________________\n",
            "dropout_273 (Dropout)        (None, 4)                 0         \n",
            "_________________________________________________________________\n",
            "dense_404 (Dense)            (None, 1)                 5         \n",
            "_________________________________________________________________\n",
            "dropout_274 (Dropout)        (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "dense_405 (Dense)            (None, 4)                 8         \n",
            "=================================================================\n",
            "Total params: 66\n",
            "Trainable params: 66\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 1668 samples, validate on 186 samples\n",
            "Epoch 1/20\n",
            "1632/1668 [============================>.] - ETA: 0s - loss: 1.6789"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1668/1668 [==============================] - 7s 4ms/sample - loss: 1.6722 - val_loss: 1.4203\n",
            "Epoch 2/20\n",
            "1668/1668 [==============================] - 0s 109us/sample - loss: 1.5639 - val_loss: 1.3358\n",
            "Epoch 3/20\n",
            "1668/1668 [==============================] - 0s 110us/sample - loss: 1.4787 - val_loss: 1.2674\n",
            "Epoch 4/20\n",
            "1668/1668 [==============================] - 0s 110us/sample - loss: 1.4070 - val_loss: 1.2114\n",
            "Epoch 5/20\n",
            "1668/1668 [==============================] - 0s 106us/sample - loss: 1.3512 - val_loss: 1.1649\n",
            "Epoch 6/20\n",
            "1668/1668 [==============================] - 0s 104us/sample - loss: 1.3058 - val_loss: 1.1250\n",
            "Epoch 7/20\n",
            "1668/1668 [==============================] - 0s 109us/sample - loss: 1.2656 - val_loss: 1.0921\n",
            "Epoch 8/20\n",
            "1668/1668 [==============================] - 0s 108us/sample - loss: 1.2335 - val_loss: 1.0637\n",
            "Epoch 9/20\n",
            "1668/1668 [==============================] - 0s 108us/sample - loss: 1.2051 - val_loss: 1.0389\n",
            "Epoch 10/20\n",
            "1668/1668 [==============================] - 0s 108us/sample - loss: 1.1802 - val_loss: 1.0172\n",
            "Epoch 11/20\n",
            "1668/1668 [==============================] - 0s 107us/sample - loss: 1.1587 - val_loss: 0.9976\n",
            "Epoch 12/20\n",
            "1668/1668 [==============================] - 0s 103us/sample - loss: 1.1391 - val_loss: 0.9798\n",
            "Epoch 13/20\n",
            "1668/1668 [==============================] - 0s 106us/sample - loss: 1.1210 - val_loss: 0.9635\n",
            "Epoch 14/20\n",
            "1668/1668 [==============================] - 0s 108us/sample - loss: 1.1047 - val_loss: 0.9484\n",
            "Epoch 15/20\n",
            "1668/1668 [==============================] - 0s 111us/sample - loss: 1.0895 - val_loss: 0.9342\n",
            "Epoch 16/20\n",
            "1668/1668 [==============================] - 0s 109us/sample - loss: 1.0750 - val_loss: 0.9210\n",
            "Epoch 17/20\n",
            "1668/1668 [==============================] - 0s 110us/sample - loss: 1.0616 - val_loss: 0.9084\n",
            "Epoch 18/20\n",
            "1668/1668 [==============================] - 0s 108us/sample - loss: 1.0490 - val_loss: 0.8966\n",
            "Epoch 19/20\n",
            "1668/1668 [==============================] - 0s 108us/sample - loss: 1.0371 - val_loss: 0.8854\n",
            "Epoch 20/20\n",
            "1668/1668 [==============================] - 0s 107us/sample - loss: 1.0258 - val_loss: 0.8747\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
            "  warnings.warn(\"Numerical issues were encountered \"\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/src/tods/tods/searcher/brute_force_search.py\", line 62, in _search\n",
            "    for error in pipeline_result.error:\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "Not all provided hyper-parameters for the data preparation pipeline 79ce71bd-db96-494b-a455-14f2e2ac5040 were used: ['method', 'number_of_folds', 'randomSeed', 'shuffle', 'stratified']\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
            "  warnings.warn(\"Numerical issues were encountered \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_31\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_406 (Dense)            (None, 4)                 20        \n",
            "_________________________________________________________________\n",
            "dropout_275 (Dropout)        (None, 4)                 0         \n",
            "_________________________________________________________________\n",
            "dense_407 (Dense)            (None, 4)                 20        \n",
            "_________________________________________________________________\n",
            "dropout_276 (Dropout)        (None, 4)                 0         \n",
            "_________________________________________________________________\n",
            "dense_408 (Dense)            (None, 1)                 5         \n",
            "_________________________________________________________________\n",
            "dropout_277 (Dropout)        (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "dense_409 (Dense)            (None, 4)                 8         \n",
            "_________________________________________________________________\n",
            "dropout_278 (Dropout)        (None, 4)                 0         \n",
            "_________________________________________________________________\n",
            "dense_410 (Dense)            (None, 1)                 5         \n",
            "_________________________________________________________________\n",
            "dropout_279 (Dropout)        (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "dense_411 (Dense)            (None, 4)                 8         \n",
            "=================================================================\n",
            "Total params: 66\n",
            "Trainable params: 66\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 1668 samples, validate on 186 samples\n",
            "Epoch 1/20\n",
            "1632/1668 [============================>.] - ETA: 0s - loss: 1.4423"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1668/1668 [==============================] - 7s 4ms/sample - loss: 1.4377 - val_loss: 1.4380\n",
            "Epoch 2/20\n",
            "1668/1668 [==============================] - 0s 109us/sample - loss: 1.3653 - val_loss: 1.3926\n",
            "Epoch 3/20\n",
            "1668/1668 [==============================] - 0s 110us/sample - loss: 1.3198 - val_loss: 1.3560\n",
            "Epoch 4/20\n",
            "1668/1668 [==============================] - 0s 109us/sample - loss: 1.2821 - val_loss: 1.3258\n",
            "Epoch 5/20\n",
            "1668/1668 [==============================] - 0s 109us/sample - loss: 1.2525 - val_loss: 1.2998\n",
            "Epoch 6/20\n",
            "1668/1668 [==============================] - 0s 108us/sample - loss: 1.2267 - val_loss: 1.2764\n",
            "Epoch 7/20\n",
            "1668/1668 [==============================] - 0s 108us/sample - loss: 1.2056 - val_loss: 1.2540\n",
            "Epoch 8/20\n",
            "1668/1668 [==============================] - 0s 109us/sample - loss: 1.1829 - val_loss: 1.2343\n",
            "Epoch 9/20\n",
            "1668/1668 [==============================] - 0s 111us/sample - loss: 1.1633 - val_loss: 1.2157\n",
            "Epoch 10/20\n",
            "1668/1668 [==============================] - 0s 111us/sample - loss: 1.1441 - val_loss: 1.1984\n",
            "Epoch 11/20\n",
            "1668/1668 [==============================] - 0s 111us/sample - loss: 1.1267 - val_loss: 1.1817\n",
            "Epoch 12/20\n",
            "1668/1668 [==============================] - 0s 107us/sample - loss: 1.1099 - val_loss: 1.1660\n",
            "Epoch 13/20\n",
            "1668/1668 [==============================] - 0s 110us/sample - loss: 1.0940 - val_loss: 1.1509\n",
            "Epoch 14/20\n",
            "1668/1668 [==============================] - 0s 111us/sample - loss: 1.0789 - val_loss: 1.1368\n",
            "Epoch 15/20\n",
            "1668/1668 [==============================] - 0s 108us/sample - loss: 1.0646 - val_loss: 1.1232\n",
            "Epoch 16/20\n",
            "1668/1668 [==============================] - 0s 110us/sample - loss: 1.0511 - val_loss: 1.1105\n",
            "Epoch 17/20\n",
            "1668/1668 [==============================] - 0s 109us/sample - loss: 1.0383 - val_loss: 1.0984\n",
            "Epoch 18/20\n",
            "1668/1668 [==============================] - 0s 109us/sample - loss: 1.0260 - val_loss: 1.0869\n",
            "Epoch 19/20\n",
            "1668/1668 [==============================] - 0s 107us/sample - loss: 1.0144 - val_loss: 1.0759\n",
            "Epoch 20/20\n",
            "1668/1668 [==============================] - 0s 111us/sample - loss: 1.0033 - val_loss: 1.0654\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
            "  warnings.warn(\"Numerical issues were encountered \"\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/src/tods/tods/searcher/brute_force_search.py\", line 62, in _search\n",
            "    for error in pipeline_result.error:\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "Not all provided hyper-parameters for the data preparation pipeline 79ce71bd-db96-494b-a455-14f2e2ac5040 were used: ['method', 'number_of_folds', 'randomSeed', 'shuffle', 'stratified']\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
            "  warnings.warn(\"Numerical issues were encountered \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_32\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_412 (Dense)            (None, 4)                 20        \n",
            "_________________________________________________________________\n",
            "dropout_280 (Dropout)        (None, 4)                 0         \n",
            "_________________________________________________________________\n",
            "dense_413 (Dense)            (None, 4)                 20        \n",
            "_________________________________________________________________\n",
            "dropout_281 (Dropout)        (None, 4)                 0         \n",
            "_________________________________________________________________\n",
            "dense_414 (Dense)            (None, 1)                 5         \n",
            "_________________________________________________________________\n",
            "dropout_282 (Dropout)        (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "dense_415 (Dense)            (None, 4)                 8         \n",
            "_________________________________________________________________\n",
            "dropout_283 (Dropout)        (None, 4)                 0         \n",
            "_________________________________________________________________\n",
            "dense_416 (Dense)            (None, 1)                 5         \n",
            "_________________________________________________________________\n",
            "dropout_284 (Dropout)        (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "dense_417 (Dense)            (None, 4)                 8         \n",
            "=================================================================\n",
            "Total params: 66\n",
            "Trainable params: 66\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 1668 samples, validate on 186 samples\n",
            "Epoch 1/20\n",
            "1504/1668 [==========================>...] - ETA: 0s - loss: 1.6261"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1668/1668 [==============================] - 7s 4ms/sample - loss: 1.5928 - val_loss: 1.3018\n",
            "Epoch 2/20\n",
            "1668/1668 [==============================] - 0s 114us/sample - loss: 1.4996 - val_loss: 1.2399\n",
            "Epoch 3/20\n",
            "1668/1668 [==============================] - 0s 114us/sample - loss: 1.4290 - val_loss: 1.1933\n",
            "Epoch 4/20\n",
            "1668/1668 [==============================] - 0s 113us/sample - loss: 1.3782 - val_loss: 1.1560\n",
            "Epoch 5/20\n",
            "1668/1668 [==============================] - 0s 111us/sample - loss: 1.3362 - val_loss: 1.1252\n",
            "Epoch 6/20\n",
            "1668/1668 [==============================] - 0s 112us/sample - loss: 1.2999 - val_loss: 1.0981\n",
            "Epoch 7/20\n",
            "1668/1668 [==============================] - 0s 111us/sample - loss: 1.2705 - val_loss: 1.0734\n",
            "Epoch 8/20\n",
            "1668/1668 [==============================] - 0s 110us/sample - loss: 1.2420 - val_loss: 1.0510\n",
            "Epoch 9/20\n",
            "1668/1668 [==============================] - 0s 109us/sample - loss: 1.2175 - val_loss: 1.0300\n",
            "Epoch 10/20\n",
            "1668/1668 [==============================] - 0s 107us/sample - loss: 1.1950 - val_loss: 1.0105\n",
            "Epoch 11/20\n",
            "1668/1668 [==============================] - 0s 110us/sample - loss: 1.1735 - val_loss: 0.9923\n",
            "Epoch 12/20\n",
            "1668/1668 [==============================] - 0s 108us/sample - loss: 1.1538 - val_loss: 0.9752\n",
            "Epoch 13/20\n",
            "1668/1668 [==============================] - 0s 107us/sample - loss: 1.1355 - val_loss: 0.9591\n",
            "Epoch 14/20\n",
            "1668/1668 [==============================] - 0s 108us/sample - loss: 1.1182 - val_loss: 0.9440\n",
            "Epoch 15/20\n",
            "1668/1668 [==============================] - 0s 108us/sample - loss: 1.1016 - val_loss: 0.9297\n",
            "Epoch 16/20\n",
            "1668/1668 [==============================] - 0s 108us/sample - loss: 1.0863 - val_loss: 0.9161\n",
            "Epoch 17/20\n",
            "1668/1668 [==============================] - 0s 108us/sample - loss: 1.0719 - val_loss: 0.9033\n",
            "Epoch 18/20\n",
            "1668/1668 [==============================] - 0s 110us/sample - loss: 1.0583 - val_loss: 0.8913\n",
            "Epoch 19/20\n",
            "1668/1668 [==============================] - 0s 107us/sample - loss: 1.0456 - val_loss: 0.8800\n",
            "Epoch 20/20\n",
            "1668/1668 [==============================] - 0s 111us/sample - loss: 1.0337 - val_loss: 0.8691\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
            "  warnings.warn(\"Numerical issues were encountered \"\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/src/tods/tods/searcher/brute_force_search.py\", line 62, in _search\n",
            "    for error in pipeline_result.error:\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "Not all provided hyper-parameters for the data preparation pipeline 79ce71bd-db96-494b-a455-14f2e2ac5040 were used: ['method', 'number_of_folds', 'randomSeed', 'shuffle', 'stratified']\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
            "  warnings.warn(\"Numerical issues were encountered \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_33\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_418 (Dense)            (None, 4)                 20        \n",
            "_________________________________________________________________\n",
            "dropout_285 (Dropout)        (None, 4)                 0         \n",
            "_________________________________________________________________\n",
            "dense_419 (Dense)            (None, 4)                 20        \n",
            "_________________________________________________________________\n",
            "dropout_286 (Dropout)        (None, 4)                 0         \n",
            "_________________________________________________________________\n",
            "dense_420 (Dense)            (None, 1)                 5         \n",
            "_________________________________________________________________\n",
            "dropout_287 (Dropout)        (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "dense_421 (Dense)            (None, 4)                 8         \n",
            "_________________________________________________________________\n",
            "dropout_288 (Dropout)        (None, 4)                 0         \n",
            "_________________________________________________________________\n",
            "dense_422 (Dense)            (None, 1)                 5         \n",
            "_________________________________________________________________\n",
            "dropout_289 (Dropout)        (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "dense_423 (Dense)            (None, 4)                 8         \n",
            "=================================================================\n",
            "Total params: 66\n",
            "Trainable params: 66\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 1668 samples, validate on 186 samples\n",
            "Epoch 1/20\n",
            "1536/1668 [==========================>...] - ETA: 0s - loss: 1.5677"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1668/1668 [==============================] - 7s 4ms/sample - loss: 1.5483 - val_loss: 1.6659\n",
            "Epoch 2/20\n",
            "1668/1668 [==============================] - 0s 116us/sample - loss: 1.4412 - val_loss: 1.5736\n",
            "Epoch 3/20\n",
            "1668/1668 [==============================] - 0s 116us/sample - loss: 1.3704 - val_loss: 1.4933\n",
            "Epoch 4/20\n",
            "1668/1668 [==============================] - 0s 118us/sample - loss: 1.2949 - val_loss: 1.4285\n",
            "Epoch 5/20\n",
            "1668/1668 [==============================] - 0s 121us/sample - loss: 1.2508 - val_loss: 1.3724\n",
            "Epoch 6/20\n",
            "1668/1668 [==============================] - 0s 116us/sample - loss: 1.1990 - val_loss: 1.3242\n",
            "Epoch 7/20\n",
            "1668/1668 [==============================] - 0s 116us/sample - loss: 1.1607 - val_loss: 1.2836\n",
            "Epoch 8/20\n",
            "1668/1668 [==============================] - 0s 117us/sample - loss: 1.1209 - val_loss: 1.2470\n",
            "Epoch 9/20\n",
            "1668/1668 [==============================] - 0s 115us/sample - loss: 1.0934 - val_loss: 1.2156\n",
            "Epoch 10/20\n",
            "1668/1668 [==============================] - 0s 112us/sample - loss: 1.0686 - val_loss: 1.1897\n",
            "Epoch 11/20\n",
            "1668/1668 [==============================] - 0s 111us/sample - loss: 1.0424 - val_loss: 1.1659\n",
            "Epoch 12/20\n",
            "1668/1668 [==============================] - 0s 111us/sample - loss: 1.0242 - val_loss: 1.1450\n",
            "Epoch 13/20\n",
            "1668/1668 [==============================] - 0s 114us/sample - loss: 0.9999 - val_loss: 1.1249\n",
            "Epoch 14/20\n",
            "1668/1668 [==============================] - 0s 112us/sample - loss: 0.9905 - val_loss: 1.1101\n",
            "Epoch 15/20\n",
            "1668/1668 [==============================] - 0s 114us/sample - loss: 0.9723 - val_loss: 1.0952\n",
            "Epoch 16/20\n",
            "1668/1668 [==============================] - 0s 114us/sample - loss: 0.9621 - val_loss: 1.0832\n",
            "Epoch 17/20\n",
            "1668/1668 [==============================] - 0s 117us/sample - loss: 0.9504 - val_loss: 1.0711\n",
            "Epoch 18/20\n",
            "1668/1668 [==============================] - 0s 118us/sample - loss: 0.9448 - val_loss: 1.0620\n",
            "Epoch 19/20\n",
            "1668/1668 [==============================] - 0s 118us/sample - loss: 0.9313 - val_loss: 1.0519\n",
            "Epoch 20/20\n",
            "1668/1668 [==============================] - 0s 116us/sample - loss: 0.9252 - val_loss: 1.0434\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
            "  warnings.warn(\"Numerical issues were encountered \"\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/src/tods/tods/searcher/brute_force_search.py\", line 62, in _search\n",
            "    for error in pipeline_result.error:\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "Not all provided hyper-parameters for the data preparation pipeline 79ce71bd-db96-494b-a455-14f2e2ac5040 were used: ['method', 'number_of_folds', 'randomSeed', 'shuffle', 'stratified']\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
            "  warnings.warn(\"Numerical issues were encountered \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_60\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_41 (InputLayer)           [(None, 4)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_424 (Dense)               (None, 4)            20          input_41[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_425 (Dense)               (None, 1)            5           dense_424[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_290 (Dropout)           (None, 1)            0           dense_425[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_426 (Dense)               (None, 4)            8           dropout_290[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_291 (Dropout)           (None, 4)            0           dense_426[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_427 (Dense)               (None, 1)            5           dropout_291[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_292 (Dropout)           (None, 1)            0           dense_427[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_428 (Dense)               (None, 2)            4           dropout_292[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_429 (Dense)               (None, 2)            4           dropout_292[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_20 (Lambda)              (None, 2)            0           dense_428[0][0]                  \n",
            "                                                                 dense_429[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 46\n",
            "Trainable params: 46\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model_61\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_42 (InputLayer)        [(None, 2)]               0         \n",
            "_________________________________________________________________\n",
            "dense_430 (Dense)            (None, 2)                 6         \n",
            "_________________________________________________________________\n",
            "dense_431 (Dense)            (None, 4)                 12        \n",
            "_________________________________________________________________\n",
            "dropout_293 (Dropout)        (None, 4)                 0         \n",
            "_________________________________________________________________\n",
            "dense_432 (Dense)            (None, 4)                 20        \n",
            "_________________________________________________________________\n",
            "dropout_294 (Dropout)        (None, 4)                 0         \n",
            "_________________________________________________________________\n",
            "dense_433 (Dense)            (None, 4)                 20        \n",
            "_________________________________________________________________\n",
            "dropout_295 (Dropout)        (None, 4)                 0         \n",
            "_________________________________________________________________\n",
            "dense_434 (Dense)            (None, 4)                 20        \n",
            "=================================================================\n",
            "Total params: 78\n",
            "Trainable params: 78\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:Output model_61 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to model_61.\n",
            "Model: \"model_62\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_41 (InputLayer)           [(None, 4)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "model_60 (Functional)           [(None, 2), (None, 2 46          input_41[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "model_61 (Functional)           (None, 4)            78          model_60[0][2]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_424 (Dense)               (None, 4)            20          input_41[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_425 (Dense)               (None, 1)            5           dense_424[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_290 (Dropout)           (None, 1)            0           dense_425[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_426 (Dense)               (None, 4)            8           dropout_290[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_291 (Dropout)           (None, 4)            0           dense_426[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_427 (Dense)               (None, 1)            5           dropout_291[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_292 (Dropout)           (None, 1)            0           dense_427[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_429 (Dense)               (None, 2)            4           dropout_292[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_428 (Dense)               (None, 2)            4           dropout_292[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_add_40 (TensorFlowO [(None, 2)]          0           dense_429[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Square_20 (TensorFl [(None, 2)]          0           dense_428[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_sub_60 (TensorFlowO [(None, 2)]          0           tf_op_layer_add_40[0][0]         \n",
            "                                                                 tf_op_layer_Square_20[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Exp_20 (TensorFlowO [(None, 2)]          0           dense_429[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_sub_61 (TensorFlowO [(None, 2)]          0           tf_op_layer_sub_60[0][0]         \n",
            "                                                                 tf_op_layer_Exp_20[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Sum_20 (TensorFlowO [(None,)]            0           tf_op_layer_sub_61[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_mul_61 (TensorFlowO [(None,)]            0           tf_op_layer_Sum_20[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_SquaredDifference_2 [(None, 4)]          0           model_61[0][0]                   \n",
            "                                                                 input_41[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_sub_62 (TensorFlowO [(None,)]            0           tf_op_layer_mul_61[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Mean_40 (TensorFlow [(None,)]            0           tf_op_layer_SquaredDifference_20[\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Abs_20 (TensorFlowO [(None,)]            0           tf_op_layer_sub_62[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_mul_60 (TensorFlowO [(None,)]            0           tf_op_layer_Mean_40[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_mul_62 (TensorFlowO [(None,)]            0           tf_op_layer_Abs_20[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_add_41 (TensorFlowO [(None,)]            0           tf_op_layer_mul_60[0][0]         \n",
            "                                                                 tf_op_layer_mul_62[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Mean_41 (TensorFlow [()]                 0           tf_op_layer_add_41[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "add_loss_20 (AddLoss)           ()                   0           tf_op_layer_Mean_41[0][0]        \n",
            "==================================================================================================\n",
            "Total params: 124\n",
            "Trainable params: 124\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1668 samples, validate on 186 samples\n",
            "Epoch 1/100\n",
            "1344/1668 [=======================>......] - ETA: 1s - loss: 5.0171"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1668/1668 [==============================] - 7s 4ms/sample - loss: 4.9163 - val_loss: 5.7030\n",
            "Epoch 2/100\n",
            "1668/1668 [==============================] - 0s 128us/sample - loss: 4.7576 - val_loss: 5.5418\n",
            "Epoch 3/100\n",
            "1668/1668 [==============================] - 0s 124us/sample - loss: 4.5061 - val_loss: 5.1829\n",
            "Epoch 4/100\n",
            "1668/1668 [==============================] - 0s 128us/sample - loss: 4.0983 - val_loss: 4.6351\n",
            "Epoch 5/100\n",
            "1668/1668 [==============================] - 0s 129us/sample - loss: 3.6781 - val_loss: 4.2400\n",
            "Epoch 6/100\n",
            "1668/1668 [==============================] - 0s 126us/sample - loss: 3.3512 - val_loss: 3.9836\n",
            "Epoch 7/100\n",
            "1668/1668 [==============================] - 0s 125us/sample - loss: 3.1903 - val_loss: 3.9352\n",
            "Epoch 8/100\n",
            "1668/1668 [==============================] - 0s 124us/sample - loss: 3.0890 - val_loss: 3.8701\n",
            "Epoch 9/100\n",
            "1668/1668 [==============================] - 0s 130us/sample - loss: 3.0523 - val_loss: 3.8515\n",
            "Epoch 10/100\n",
            "1668/1668 [==============================] - 0s 128us/sample - loss: 3.0128 - val_loss: 3.8435\n",
            "Epoch 11/100\n",
            "1668/1668 [==============================] - 0s 129us/sample - loss: 2.9970 - val_loss: 3.8269\n",
            "Epoch 12/100\n",
            "1668/1668 [==============================] - 0s 130us/sample - loss: 2.9817 - val_loss: 3.8274\n",
            "Epoch 13/100\n",
            "1668/1668 [==============================] - 0s 130us/sample - loss: 2.9763 - val_loss: 3.8313\n",
            "Epoch 14/100\n",
            "1668/1668 [==============================] - 0s 126us/sample - loss: 2.9588 - val_loss: 3.8276\n",
            "Epoch 15/100\n",
            "1668/1668 [==============================] - 0s 127us/sample - loss: 2.9673 - val_loss: 3.8280\n",
            "Epoch 16/100\n",
            "1668/1668 [==============================] - 0s 126us/sample - loss: 2.9550 - val_loss: 3.8263\n",
            "Epoch 17/100\n",
            "1668/1668 [==============================] - 0s 126us/sample - loss: 2.9500 - val_loss: 3.8266\n",
            "Epoch 18/100\n",
            "1668/1668 [==============================] - 0s 125us/sample - loss: 2.9506 - val_loss: 3.8267\n",
            "Epoch 19/100\n",
            "1668/1668 [==============================] - 0s 127us/sample - loss: 2.9439 - val_loss: 3.8259\n",
            "Epoch 20/100\n",
            "1668/1668 [==============================] - 0s 128us/sample - loss: 2.9378 - val_loss: 3.8248\n",
            "Epoch 21/100\n",
            "1668/1668 [==============================] - 0s 125us/sample - loss: 2.9359 - val_loss: 3.8256\n",
            "Epoch 22/100\n",
            "1668/1668 [==============================] - 0s 128us/sample - loss: 2.9405 - val_loss: 3.8253\n",
            "Epoch 23/100\n",
            "1668/1668 [==============================] - 0s 130us/sample - loss: 2.9267 - val_loss: 3.8257\n",
            "Epoch 24/100\n",
            "1668/1668 [==============================] - 0s 129us/sample - loss: 2.9280 - val_loss: 3.8254\n",
            "Epoch 25/100\n",
            "1668/1668 [==============================] - 0s 126us/sample - loss: 2.9242 - val_loss: 3.8254\n",
            "Epoch 26/100\n",
            "1668/1668 [==============================] - 0s 124us/sample - loss: 2.9269 - val_loss: 3.8251\n",
            "Epoch 27/100\n",
            "1668/1668 [==============================] - 0s 126us/sample - loss: 2.9209 - val_loss: 3.8253\n",
            "Epoch 28/100\n",
            "1668/1668 [==============================] - 0s 129us/sample - loss: 2.9171 - val_loss: 3.8251\n",
            "Epoch 29/100\n",
            "1668/1668 [==============================] - 0s 127us/sample - loss: 2.9275 - val_loss: 3.8251\n",
            "Epoch 30/100\n",
            "1668/1668 [==============================] - 0s 128us/sample - loss: 2.9244 - val_loss: 3.8250\n",
            "Epoch 31/100\n",
            "1668/1668 [==============================] - 0s 127us/sample - loss: 2.9231 - val_loss: 3.8251\n",
            "Epoch 32/100\n",
            "1668/1668 [==============================] - 0s 129us/sample - loss: 2.9218 - val_loss: 3.8250\n",
            "Epoch 33/100\n",
            "1668/1668 [==============================] - 0s 130us/sample - loss: 2.9193 - val_loss: 3.8251\n",
            "Epoch 34/100\n",
            "1668/1668 [==============================] - 0s 133us/sample - loss: 2.9204 - val_loss: 3.8252\n",
            "Epoch 35/100\n",
            "1668/1668 [==============================] - 0s 134us/sample - loss: 2.9136 - val_loss: 3.8251\n",
            "Epoch 36/100\n",
            "1668/1668 [==============================] - 0s 132us/sample - loss: 2.9161 - val_loss: 3.8251\n",
            "Epoch 37/100\n",
            "1668/1668 [==============================] - 0s 128us/sample - loss: 2.9131 - val_loss: 3.8251\n",
            "Epoch 38/100\n",
            "1668/1668 [==============================] - 0s 126us/sample - loss: 2.9251 - val_loss: 3.8251\n",
            "Epoch 39/100\n",
            "1668/1668 [==============================] - 0s 127us/sample - loss: 2.9172 - val_loss: 3.8251\n",
            "Epoch 40/100\n",
            "1668/1668 [==============================] - 0s 129us/sample - loss: 2.9169 - val_loss: 3.8251\n",
            "Epoch 41/100\n",
            "1668/1668 [==============================] - 0s 127us/sample - loss: 2.9212 - val_loss: 3.8251\n",
            "Epoch 42/100\n",
            "1668/1668 [==============================] - 0s 128us/sample - loss: 2.9144 - val_loss: 3.8251\n",
            "Epoch 43/100\n",
            "1668/1668 [==============================] - 0s 127us/sample - loss: 2.9127 - val_loss: 3.8251\n",
            "Epoch 44/100\n",
            "1668/1668 [==============================] - 0s 129us/sample - loss: 2.9173 - val_loss: 3.8251\n",
            "Epoch 45/100\n",
            "1668/1668 [==============================] - 0s 128us/sample - loss: 2.9184 - val_loss: 3.8251\n",
            "Epoch 46/100\n",
            "1668/1668 [==============================] - 0s 127us/sample - loss: 2.9125 - val_loss: 3.8251\n",
            "Epoch 47/100\n",
            "1668/1668 [==============================] - 0s 126us/sample - loss: 2.9161 - val_loss: 3.8251\n",
            "Epoch 48/100\n",
            "1668/1668 [==============================] - 0s 124us/sample - loss: 2.9162 - val_loss: 3.8251\n",
            "Epoch 49/100\n",
            "1668/1668 [==============================] - 0s 122us/sample - loss: 2.9163 - val_loss: 3.8251\n",
            "Epoch 50/100\n",
            "1668/1668 [==============================] - 0s 123us/sample - loss: 2.9157 - val_loss: 3.8251\n",
            "Epoch 51/100\n",
            "1668/1668 [==============================] - 0s 127us/sample - loss: 2.9125 - val_loss: 3.8251\n",
            "Epoch 52/100\n",
            "1668/1668 [==============================] - 0s 126us/sample - loss: 2.9169 - val_loss: 3.8251\n",
            "Epoch 53/100\n",
            "1668/1668 [==============================] - 0s 127us/sample - loss: 2.9201 - val_loss: 3.8251\n",
            "Epoch 54/100\n",
            "1668/1668 [==============================] - 0s 129us/sample - loss: 2.9115 - val_loss: 3.8251\n",
            "Epoch 55/100\n",
            "1668/1668 [==============================] - 0s 125us/sample - loss: 2.9142 - val_loss: 3.8251\n",
            "Epoch 56/100\n",
            "1668/1668 [==============================] - 0s 131us/sample - loss: 2.9132 - val_loss: 3.8251\n",
            "Epoch 57/100\n",
            "1668/1668 [==============================] - 0s 126us/sample - loss: 2.9121 - val_loss: 3.8251\n",
            "Epoch 58/100\n",
            "1668/1668 [==============================] - 0s 126us/sample - loss: 2.9133 - val_loss: 3.8251\n",
            "Epoch 59/100\n",
            "1668/1668 [==============================] - 0s 126us/sample - loss: 2.9100 - val_loss: 3.8251\n",
            "Epoch 60/100\n",
            "1668/1668 [==============================] - 0s 129us/sample - loss: 2.9127 - val_loss: 3.8251\n",
            "Epoch 61/100\n",
            "1668/1668 [==============================] - 0s 128us/sample - loss: 2.9121 - val_loss: 3.8251\n",
            "Epoch 62/100\n",
            "1668/1668 [==============================] - 0s 125us/sample - loss: 2.9139 - val_loss: 3.8251\n",
            "Epoch 63/100\n",
            "1668/1668 [==============================] - 0s 124us/sample - loss: 2.9153 - val_loss: 3.8251\n",
            "Epoch 64/100\n",
            "1668/1668 [==============================] - 0s 124us/sample - loss: 2.9134 - val_loss: 3.8251\n",
            "Epoch 65/100\n",
            "1668/1668 [==============================] - 0s 125us/sample - loss: 2.9146 - val_loss: 3.8251\n",
            "Epoch 66/100\n",
            "1668/1668 [==============================] - 0s 126us/sample - loss: 2.9106 - val_loss: 3.8251\n",
            "Epoch 67/100\n",
            "1668/1668 [==============================] - 0s 125us/sample - loss: 2.9140 - val_loss: 3.8251\n",
            "Epoch 68/100\n",
            "1668/1668 [==============================] - 0s 127us/sample - loss: 2.9109 - val_loss: 3.8251\n",
            "Epoch 69/100\n",
            "1668/1668 [==============================] - 0s 126us/sample - loss: 2.9131 - val_loss: 3.8251\n",
            "Epoch 70/100\n",
            "1668/1668 [==============================] - 0s 125us/sample - loss: 2.9131 - val_loss: 3.8251\n",
            "Epoch 71/100\n",
            "1668/1668 [==============================] - 0s 124us/sample - loss: 2.9143 - val_loss: 3.8251\n",
            "Epoch 72/100\n",
            "1668/1668 [==============================] - 0s 125us/sample - loss: 2.9128 - val_loss: 3.8251\n",
            "Epoch 73/100\n",
            "1668/1668 [==============================] - 0s 124us/sample - loss: 2.9158 - val_loss: 3.8251\n",
            "Epoch 74/100\n",
            "1668/1668 [==============================] - 0s 125us/sample - loss: 2.9156 - val_loss: 3.8251\n",
            "Epoch 75/100\n",
            "1668/1668 [==============================] - 0s 125us/sample - loss: 2.9128 - val_loss: 3.8251\n",
            "Epoch 76/100\n",
            "1668/1668 [==============================] - 0s 124us/sample - loss: 2.9093 - val_loss: 3.8251\n",
            "Epoch 77/100\n",
            "1668/1668 [==============================] - 0s 127us/sample - loss: 2.9103 - val_loss: 3.8251\n",
            "Epoch 78/100\n",
            "1668/1668 [==============================] - 0s 125us/sample - loss: 2.9110 - val_loss: 3.8251\n",
            "Epoch 79/100\n",
            "1668/1668 [==============================] - 0s 124us/sample - loss: 2.9153 - val_loss: 3.8251\n",
            "Epoch 80/100\n",
            "1668/1668 [==============================] - 0s 123us/sample - loss: 2.9126 - val_loss: 3.8251\n",
            "Epoch 81/100\n",
            "1668/1668 [==============================] - 0s 124us/sample - loss: 2.9106 - val_loss: 3.8251\n",
            "Epoch 82/100\n",
            "1668/1668 [==============================] - 0s 123us/sample - loss: 2.9109 - val_loss: 3.8251\n",
            "Epoch 83/100\n",
            "1668/1668 [==============================] - 0s 126us/sample - loss: 2.9094 - val_loss: 3.8251\n",
            "Epoch 84/100\n",
            "1668/1668 [==============================] - 0s 126us/sample - loss: 2.9132 - val_loss: 3.8251\n",
            "Epoch 85/100\n",
            "1668/1668 [==============================] - 0s 125us/sample - loss: 2.9119 - val_loss: 3.8251\n",
            "Epoch 86/100\n",
            "1668/1668 [==============================] - 0s 126us/sample - loss: 2.9153 - val_loss: 3.8251\n",
            "Epoch 87/100\n",
            "1668/1668 [==============================] - 0s 126us/sample - loss: 2.9084 - val_loss: 3.8251\n",
            "Epoch 88/100\n",
            "1668/1668 [==============================] - 0s 126us/sample - loss: 2.9110 - val_loss: 3.8251\n",
            "Epoch 89/100\n",
            "1668/1668 [==============================] - 0s 125us/sample - loss: 2.9116 - val_loss: 3.8251\n",
            "Epoch 90/100\n",
            "1668/1668 [==============================] - 0s 125us/sample - loss: 2.9106 - val_loss: 3.8251\n",
            "Epoch 91/100\n",
            "1668/1668 [==============================] - 0s 124us/sample - loss: 2.9088 - val_loss: 3.8251\n",
            "Epoch 92/100\n",
            "1668/1668 [==============================] - 0s 125us/sample - loss: 2.9175 - val_loss: 3.8251\n",
            "Epoch 93/100\n",
            "1668/1668 [==============================] - 0s 127us/sample - loss: 2.9094 - val_loss: 3.8251\n",
            "Epoch 94/100\n",
            "1668/1668 [==============================] - 0s 131us/sample - loss: 2.9096 - val_loss: 3.8251\n",
            "Epoch 95/100\n",
            "1668/1668 [==============================] - 0s 128us/sample - loss: 2.9095 - val_loss: 3.8251\n",
            "Epoch 96/100\n",
            "1668/1668 [==============================] - 0s 130us/sample - loss: 2.9116 - val_loss: 3.8251\n",
            "Epoch 97/100\n",
            "1668/1668 [==============================] - 0s 127us/sample - loss: 2.9114 - val_loss: 3.8251\n",
            "Epoch 98/100\n",
            "1668/1668 [==============================] - 0s 128us/sample - loss: 2.9141 - val_loss: 3.8251\n",
            "Epoch 99/100\n",
            "1668/1668 [==============================] - 0s 127us/sample - loss: 2.9115 - val_loss: 3.8251\n",
            "Epoch 100/100\n",
            "1668/1668 [==============================] - 0s 126us/sample - loss: 2.9112 - val_loss: 3.8251\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
            "  warnings.warn(\"Numerical issues were encountered \"\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/src/tods/tods/searcher/brute_force_search.py\", line 62, in _search\n",
            "    for error in pipeline_result.error:\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "Not all provided hyper-parameters for the data preparation pipeline 79ce71bd-db96-494b-a455-14f2e2ac5040 were used: ['method', 'number_of_folds', 'randomSeed', 'shuffle', 'stratified']\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
            "  warnings.warn(\"Numerical issues were encountered \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_63\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_43 (InputLayer)           [(None, 4)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_435 (Dense)               (None, 4)            20          input_43[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_436 (Dense)               (None, 1)            5           dense_435[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_296 (Dropout)           (None, 1)            0           dense_436[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_437 (Dense)               (None, 4)            8           dropout_296[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_297 (Dropout)           (None, 4)            0           dense_437[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_438 (Dense)               (None, 1)            5           dropout_297[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_298 (Dropout)           (None, 1)            0           dense_438[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_439 (Dense)               (None, 2)            4           dropout_298[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_440 (Dense)               (None, 2)            4           dropout_298[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_21 (Lambda)              (None, 2)            0           dense_439[0][0]                  \n",
            "                                                                 dense_440[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 46\n",
            "Trainable params: 46\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model_64\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_44 (InputLayer)        [(None, 2)]               0         \n",
            "_________________________________________________________________\n",
            "dense_441 (Dense)            (None, 2)                 6         \n",
            "_________________________________________________________________\n",
            "dense_442 (Dense)            (None, 4)                 12        \n",
            "_________________________________________________________________\n",
            "dropout_299 (Dropout)        (None, 4)                 0         \n",
            "_________________________________________________________________\n",
            "dense_443 (Dense)            (None, 4)                 20        \n",
            "_________________________________________________________________\n",
            "dropout_300 (Dropout)        (None, 4)                 0         \n",
            "_________________________________________________________________\n",
            "dense_444 (Dense)            (None, 4)                 20        \n",
            "_________________________________________________________________\n",
            "dropout_301 (Dropout)        (None, 4)                 0         \n",
            "_________________________________________________________________\n",
            "dense_445 (Dense)            (None, 4)                 20        \n",
            "=================================================================\n",
            "Total params: 78\n",
            "Trainable params: 78\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:Output model_64 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to model_64.\n",
            "Model: \"model_65\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_43 (InputLayer)           [(None, 4)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "model_63 (Functional)           [(None, 2), (None, 2 46          input_43[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "model_64 (Functional)           (None, 4)            78          model_63[0][2]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_435 (Dense)               (None, 4)            20          input_43[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_436 (Dense)               (None, 1)            5           dense_435[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_296 (Dropout)           (None, 1)            0           dense_436[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_437 (Dense)               (None, 4)            8           dropout_296[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_297 (Dropout)           (None, 4)            0           dense_437[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_438 (Dense)               (None, 1)            5           dropout_297[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_298 (Dropout)           (None, 1)            0           dense_438[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_440 (Dense)               (None, 2)            4           dropout_298[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_439 (Dense)               (None, 2)            4           dropout_298[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_add_42 (TensorFlowO [(None, 2)]          0           dense_440[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Square_21 (TensorFl [(None, 2)]          0           dense_439[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_sub_63 (TensorFlowO [(None, 2)]          0           tf_op_layer_add_42[0][0]         \n",
            "                                                                 tf_op_layer_Square_21[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Exp_21 (TensorFlowO [(None, 2)]          0           dense_440[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_sub_64 (TensorFlowO [(None, 2)]          0           tf_op_layer_sub_63[0][0]         \n",
            "                                                                 tf_op_layer_Exp_21[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Sum_21 (TensorFlowO [(None,)]            0           tf_op_layer_sub_64[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_mul_64 (TensorFlowO [(None,)]            0           tf_op_layer_Sum_21[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_SquaredDifference_2 [(None, 4)]          0           model_64[0][0]                   \n",
            "                                                                 input_43[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_sub_65 (TensorFlowO [(None,)]            0           tf_op_layer_mul_64[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Mean_42 (TensorFlow [(None,)]            0           tf_op_layer_SquaredDifference_21[\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Abs_21 (TensorFlowO [(None,)]            0           tf_op_layer_sub_65[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_mul_63 (TensorFlowO [(None,)]            0           tf_op_layer_Mean_42[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_mul_65 (TensorFlowO [(None,)]            0           tf_op_layer_Abs_21[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_add_43 (TensorFlowO [(None,)]            0           tf_op_layer_mul_63[0][0]         \n",
            "                                                                 tf_op_layer_mul_65[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Mean_43 (TensorFlow [()]                 0           tf_op_layer_add_43[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "add_loss_21 (AddLoss)           ()                   0           tf_op_layer_Mean_43[0][0]        \n",
            "==================================================================================================\n",
            "Total params: 124\n",
            "Trainable params: 124\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1668 samples, validate on 186 samples\n",
            "Epoch 1/100\n",
            "1344/1668 [=======================>......] - ETA: 1s - loss: 4.7281"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1668/1668 [==============================] - 8s 5ms/sample - loss: 4.6301 - val_loss: 4.6364\n",
            "Epoch 2/100\n",
            "1668/1668 [==============================] - 0s 134us/sample - loss: 4.1910 - val_loss: 4.1445\n",
            "Epoch 3/100\n",
            "1668/1668 [==============================] - 0s 133us/sample - loss: 3.8168 - val_loss: 3.7631\n",
            "Epoch 4/100\n",
            "1668/1668 [==============================] - 0s 133us/sample - loss: 3.5650 - val_loss: 3.5096\n",
            "Epoch 5/100\n",
            "1668/1668 [==============================] - 0s 132us/sample - loss: 3.3799 - val_loss: 3.3495\n",
            "Epoch 6/100\n",
            "1668/1668 [==============================] - 0s 130us/sample - loss: 3.3060 - val_loss: 3.3424\n",
            "Epoch 7/100\n",
            "1668/1668 [==============================] - 0s 134us/sample - loss: 3.2675 - val_loss: 3.2634\n",
            "Epoch 8/100\n",
            "1668/1668 [==============================] - 0s 133us/sample - loss: 3.2100 - val_loss: 3.2572\n",
            "Epoch 9/100\n",
            "1668/1668 [==============================] - 0s 133us/sample - loss: 3.1893 - val_loss: 3.2501\n",
            "Epoch 10/100\n",
            "1668/1668 [==============================] - 0s 131us/sample - loss: 3.1396 - val_loss: 3.2384\n",
            "Epoch 11/100\n",
            "1668/1668 [==============================] - 0s 133us/sample - loss: 3.1437 - val_loss: 3.2354\n",
            "Epoch 12/100\n",
            "1668/1668 [==============================] - 0s 131us/sample - loss: 3.0918 - val_loss: 3.2415\n",
            "Epoch 13/100\n",
            "1668/1668 [==============================] - 0s 131us/sample - loss: 3.0949 - val_loss: 3.2338\n",
            "Epoch 14/100\n",
            "1668/1668 [==============================] - 0s 130us/sample - loss: 3.1008 - val_loss: 3.2341\n",
            "Epoch 15/100\n",
            "1668/1668 [==============================] - 0s 132us/sample - loss: 3.0740 - val_loss: 3.2330\n",
            "Epoch 16/100\n",
            "1668/1668 [==============================] - 0s 132us/sample - loss: 3.0790 - val_loss: 3.2325\n",
            "Epoch 17/100\n",
            "1668/1668 [==============================] - 0s 132us/sample - loss: 3.0631 - val_loss: 3.2333\n",
            "Epoch 18/100\n",
            "1668/1668 [==============================] - 0s 132us/sample - loss: 3.0527 - val_loss: 3.2327\n",
            "Epoch 19/100\n",
            "1668/1668 [==============================] - 0s 132us/sample - loss: 3.0509 - val_loss: 3.2327\n",
            "Epoch 20/100\n",
            "1668/1668 [==============================] - 0s 133us/sample - loss: 3.0497 - val_loss: 3.2325\n",
            "Epoch 21/100\n",
            "1668/1668 [==============================] - 0s 132us/sample - loss: 3.0390 - val_loss: 3.2326\n",
            "Epoch 22/100\n",
            "1668/1668 [==============================] - 0s 131us/sample - loss: 3.0275 - val_loss: 3.2326\n",
            "Epoch 23/100\n",
            "1668/1668 [==============================] - 0s 132us/sample - loss: 3.0297 - val_loss: 3.2325\n",
            "Epoch 24/100\n",
            "1668/1668 [==============================] - 0s 131us/sample - loss: 3.0281 - val_loss: 3.2326\n",
            "Epoch 25/100\n",
            "1668/1668 [==============================] - 0s 131us/sample - loss: 3.0410 - val_loss: 3.2325\n",
            "Epoch 26/100\n",
            "1668/1668 [==============================] - 0s 131us/sample - loss: 3.0404 - val_loss: 3.2325\n",
            "Epoch 27/100\n",
            "1668/1668 [==============================] - 0s 131us/sample - loss: 3.0224 - val_loss: 3.2325\n",
            "Epoch 28/100\n",
            "1668/1668 [==============================] - 0s 130us/sample - loss: 3.0126 - val_loss: 3.2325\n",
            "Epoch 29/100\n",
            "1668/1668 [==============================] - 0s 132us/sample - loss: 3.0280 - val_loss: 3.2326\n",
            "Epoch 30/100\n",
            "1668/1668 [==============================] - 0s 135us/sample - loss: 3.0296 - val_loss: 3.2325\n",
            "Epoch 31/100\n",
            "1668/1668 [==============================] - 0s 132us/sample - loss: 3.0211 - val_loss: 3.2326\n",
            "Epoch 32/100\n",
            "1668/1668 [==============================] - 0s 133us/sample - loss: 3.0110 - val_loss: 3.2325\n",
            "Epoch 33/100\n",
            "1668/1668 [==============================] - 0s 132us/sample - loss: 3.0062 - val_loss: 3.2325\n",
            "Epoch 34/100\n",
            "1668/1668 [==============================] - 0s 132us/sample - loss: 3.0119 - val_loss: 3.2325\n",
            "Epoch 35/100\n",
            "1668/1668 [==============================] - 0s 131us/sample - loss: 3.0033 - val_loss: 3.2325\n",
            "Epoch 36/100\n",
            "1668/1668 [==============================] - 0s 132us/sample - loss: 3.0027 - val_loss: 3.2325\n",
            "Epoch 37/100\n",
            "1668/1668 [==============================] - 0s 132us/sample - loss: 3.0024 - val_loss: 3.2325\n",
            "Epoch 38/100\n",
            "1668/1668 [==============================] - 0s 133us/sample - loss: 2.9970 - val_loss: 3.2325\n",
            "Epoch 39/100\n",
            "1668/1668 [==============================] - 0s 133us/sample - loss: 2.9963 - val_loss: 3.2325\n",
            "Epoch 40/100\n",
            "1668/1668 [==============================] - 0s 132us/sample - loss: 2.9998 - val_loss: 3.2325\n",
            "Epoch 41/100\n",
            "1668/1668 [==============================] - 0s 133us/sample - loss: 2.9998 - val_loss: 3.2325\n",
            "Epoch 42/100\n",
            "1668/1668 [==============================] - 0s 134us/sample - loss: 2.9990 - val_loss: 3.2325\n",
            "Epoch 43/100\n",
            "1668/1668 [==============================] - 0s 134us/sample - loss: 2.9920 - val_loss: 3.2325\n",
            "Epoch 44/100\n",
            "1668/1668 [==============================] - 0s 137us/sample - loss: 2.9994 - val_loss: 3.2325\n",
            "Epoch 45/100\n",
            "1668/1668 [==============================] - 0s 144us/sample - loss: 2.9984 - val_loss: 3.2325\n",
            "Epoch 46/100\n",
            "1668/1668 [==============================] - 0s 134us/sample - loss: 2.9940 - val_loss: 3.2325\n",
            "Epoch 47/100\n",
            "1668/1668 [==============================] - 0s 136us/sample - loss: 2.9915 - val_loss: 3.2325\n",
            "Epoch 48/100\n",
            "1668/1668 [==============================] - 0s 132us/sample - loss: 2.9912 - val_loss: 3.2325\n",
            "Epoch 49/100\n",
            "1668/1668 [==============================] - 0s 134us/sample - loss: 2.9859 - val_loss: 3.2325\n",
            "Epoch 50/100\n",
            "1668/1668 [==============================] - 0s 135us/sample - loss: 2.9921 - val_loss: 3.2325\n",
            "Epoch 51/100\n",
            "1668/1668 [==============================] - 0s 136us/sample - loss: 2.9962 - val_loss: 3.2325\n",
            "Epoch 52/100\n",
            "1668/1668 [==============================] - 0s 134us/sample - loss: 2.9889 - val_loss: 3.2325\n",
            "Epoch 53/100\n",
            "1668/1668 [==============================] - 0s 135us/sample - loss: 2.9873 - val_loss: 3.2325\n",
            "Epoch 54/100\n",
            "1668/1668 [==============================] - 0s 136us/sample - loss: 2.9900 - val_loss: 3.2325\n",
            "Epoch 55/100\n",
            "1668/1668 [==============================] - 0s 138us/sample - loss: 2.9898 - val_loss: 3.2325\n",
            "Epoch 56/100\n",
            "1668/1668 [==============================] - 0s 136us/sample - loss: 2.9859 - val_loss: 3.2325\n",
            "Epoch 57/100\n",
            "1668/1668 [==============================] - 0s 135us/sample - loss: 2.9950 - val_loss: 3.2325\n",
            "Epoch 58/100\n",
            "1668/1668 [==============================] - 0s 131us/sample - loss: 2.9905 - val_loss: 3.2325\n",
            "Epoch 59/100\n",
            "1668/1668 [==============================] - 0s 131us/sample - loss: 2.9901 - val_loss: 3.2325\n",
            "Epoch 60/100\n",
            "1668/1668 [==============================] - 0s 132us/sample - loss: 2.9928 - val_loss: 3.2325\n",
            "Epoch 61/100\n",
            "1668/1668 [==============================] - 0s 132us/sample - loss: 2.9882 - val_loss: 3.2325\n",
            "Epoch 62/100\n",
            "1668/1668 [==============================] - 0s 130us/sample - loss: 2.9842 - val_loss: 3.2325\n",
            "Epoch 63/100\n",
            "1668/1668 [==============================] - 0s 131us/sample - loss: 2.9837 - val_loss: 3.2325\n",
            "Epoch 64/100\n",
            "1668/1668 [==============================] - 0s 133us/sample - loss: 2.9907 - val_loss: 3.2325\n",
            "Epoch 65/100\n",
            "1668/1668 [==============================] - 0s 131us/sample - loss: 2.9818 - val_loss: 3.2325\n",
            "Epoch 66/100\n",
            "1668/1668 [==============================] - 0s 130us/sample - loss: 2.9817 - val_loss: 3.2325\n",
            "Epoch 67/100\n",
            "1668/1668 [==============================] - 0s 130us/sample - loss: 2.9889 - val_loss: 3.2325\n",
            "Epoch 68/100\n",
            "1668/1668 [==============================] - 0s 131us/sample - loss: 2.9889 - val_loss: 3.2325\n",
            "Epoch 69/100\n",
            "1668/1668 [==============================] - 0s 132us/sample - loss: 2.9805 - val_loss: 3.2325\n",
            "Epoch 70/100\n",
            "1668/1668 [==============================] - 0s 132us/sample - loss: 2.9842 - val_loss: 3.2325\n",
            "Epoch 71/100\n",
            "1668/1668 [==============================] - 0s 129us/sample - loss: 2.9822 - val_loss: 3.2325\n",
            "Epoch 72/100\n",
            "1668/1668 [==============================] - 0s 130us/sample - loss: 2.9900 - val_loss: 3.2325\n",
            "Epoch 73/100\n",
            "1668/1668 [==============================] - 0s 129us/sample - loss: 2.9857 - val_loss: 3.2325\n",
            "Epoch 74/100\n",
            "1668/1668 [==============================] - 0s 130us/sample - loss: 2.9807 - val_loss: 3.2325\n",
            "Epoch 75/100\n",
            "1668/1668 [==============================] - 0s 129us/sample - loss: 2.9894 - val_loss: 3.2325\n",
            "Epoch 76/100\n",
            "1668/1668 [==============================] - 0s 131us/sample - loss: 2.9840 - val_loss: 3.2325\n",
            "Epoch 77/100\n",
            "1668/1668 [==============================] - 0s 131us/sample - loss: 2.9797 - val_loss: 3.2325\n",
            "Epoch 78/100\n",
            "1668/1668 [==============================] - 0s 129us/sample - loss: 2.9809 - val_loss: 3.2325\n",
            "Epoch 79/100\n",
            "1668/1668 [==============================] - 0s 128us/sample - loss: 2.9783 - val_loss: 3.2325\n",
            "Epoch 80/100\n",
            "1668/1668 [==============================] - 0s 125us/sample - loss: 2.9823 - val_loss: 3.2325\n",
            "Epoch 81/100\n",
            "1668/1668 [==============================] - 0s 128us/sample - loss: 2.9840 - val_loss: 3.2325\n",
            "Epoch 82/100\n",
            "1668/1668 [==============================] - 0s 128us/sample - loss: 2.9791 - val_loss: 3.2325\n",
            "Epoch 83/100\n",
            "1668/1668 [==============================] - 0s 128us/sample - loss: 2.9885 - val_loss: 3.2325\n",
            "Epoch 84/100\n",
            "1668/1668 [==============================] - 0s 128us/sample - loss: 2.9810 - val_loss: 3.2325\n",
            "Epoch 85/100\n",
            "1668/1668 [==============================] - 0s 128us/sample - loss: 2.9842 - val_loss: 3.2325\n",
            "Epoch 86/100\n",
            "1668/1668 [==============================] - 0s 129us/sample - loss: 2.9839 - val_loss: 3.2325\n",
            "Epoch 87/100\n",
            "1668/1668 [==============================] - 0s 128us/sample - loss: 2.9804 - val_loss: 3.2325\n",
            "Epoch 88/100\n",
            "1668/1668 [==============================] - 0s 130us/sample - loss: 2.9799 - val_loss: 3.2325\n",
            "Epoch 89/100\n",
            "1668/1668 [==============================] - 0s 130us/sample - loss: 2.9839 - val_loss: 3.2325\n",
            "Epoch 90/100\n",
            "1668/1668 [==============================] - 0s 128us/sample - loss: 2.9836 - val_loss: 3.2325\n",
            "Epoch 91/100\n",
            "1668/1668 [==============================] - 0s 132us/sample - loss: 2.9831 - val_loss: 3.2325\n",
            "Epoch 92/100\n",
            "1668/1668 [==============================] - 0s 128us/sample - loss: 2.9825 - val_loss: 3.2325\n",
            "Epoch 93/100\n",
            "1668/1668 [==============================] - 0s 127us/sample - loss: 2.9823 - val_loss: 3.2325\n",
            "Epoch 94/100\n",
            "1668/1668 [==============================] - 0s 127us/sample - loss: 2.9871 - val_loss: 3.2325\n",
            "Epoch 95/100\n",
            "1668/1668 [==============================] - 0s 131us/sample - loss: 2.9805 - val_loss: 3.2325\n",
            "Epoch 96/100\n",
            "1668/1668 [==============================] - 0s 132us/sample - loss: 2.9826 - val_loss: 3.2325\n",
            "Epoch 97/100\n",
            "1668/1668 [==============================] - 0s 131us/sample - loss: 2.9783 - val_loss: 3.2325\n",
            "Epoch 98/100\n",
            "1668/1668 [==============================] - 0s 128us/sample - loss: 2.9848 - val_loss: 3.2325\n",
            "Epoch 99/100\n",
            "1668/1668 [==============================] - 0s 129us/sample - loss: 2.9857 - val_loss: 3.2325\n",
            "Epoch 100/100\n",
            "1668/1668 [==============================] - 0s 131us/sample - loss: 2.9850 - val_loss: 3.2325\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
            "  warnings.warn(\"Numerical issues were encountered \"\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/src/tods/tods/searcher/brute_force_search.py\", line 62, in _search\n",
            "    for error in pipeline_result.error:\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "Not all provided hyper-parameters for the data preparation pipeline 79ce71bd-db96-494b-a455-14f2e2ac5040 were used: ['method', 'number_of_folds', 'randomSeed', 'shuffle', 'stratified']\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
            "  warnings.warn(\"Numerical issues were encountered \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_66\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_45 (InputLayer)           [(None, 4)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_446 (Dense)               (None, 4)            20          input_45[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_447 (Dense)               (None, 1)            5           dense_446[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_302 (Dropout)           (None, 1)            0           dense_447[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_448 (Dense)               (None, 4)            8           dropout_302[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_303 (Dropout)           (None, 4)            0           dense_448[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_449 (Dense)               (None, 1)            5           dropout_303[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_304 (Dropout)           (None, 1)            0           dense_449[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_450 (Dense)               (None, 2)            4           dropout_304[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_451 (Dense)               (None, 2)            4           dropout_304[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_22 (Lambda)              (None, 2)            0           dense_450[0][0]                  \n",
            "                                                                 dense_451[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 46\n",
            "Trainable params: 46\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model_67\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_46 (InputLayer)        [(None, 2)]               0         \n",
            "_________________________________________________________________\n",
            "dense_452 (Dense)            (None, 2)                 6         \n",
            "_________________________________________________________________\n",
            "dense_453 (Dense)            (None, 4)                 12        \n",
            "_________________________________________________________________\n",
            "dropout_305 (Dropout)        (None, 4)                 0         \n",
            "_________________________________________________________________\n",
            "dense_454 (Dense)            (None, 4)                 20        \n",
            "_________________________________________________________________\n",
            "dropout_306 (Dropout)        (None, 4)                 0         \n",
            "_________________________________________________________________\n",
            "dense_455 (Dense)            (None, 4)                 20        \n",
            "_________________________________________________________________\n",
            "dropout_307 (Dropout)        (None, 4)                 0         \n",
            "_________________________________________________________________\n",
            "dense_456 (Dense)            (None, 4)                 20        \n",
            "=================================================================\n",
            "Total params: 78\n",
            "Trainable params: 78\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:Output model_67 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to model_67.\n",
            "Model: \"model_68\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_45 (InputLayer)           [(None, 4)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "model_66 (Functional)           [(None, 2), (None, 2 46          input_45[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "model_67 (Functional)           (None, 4)            78          model_66[0][2]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_446 (Dense)               (None, 4)            20          input_45[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_447 (Dense)               (None, 1)            5           dense_446[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_302 (Dropout)           (None, 1)            0           dense_447[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_448 (Dense)               (None, 4)            8           dropout_302[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_303 (Dropout)           (None, 4)            0           dense_448[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_449 (Dense)               (None, 1)            5           dropout_303[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_304 (Dropout)           (None, 1)            0           dense_449[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_451 (Dense)               (None, 2)            4           dropout_304[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_450 (Dense)               (None, 2)            4           dropout_304[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_add_44 (TensorFlowO [(None, 2)]          0           dense_451[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Square_22 (TensorFl [(None, 2)]          0           dense_450[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_sub_66 (TensorFlowO [(None, 2)]          0           tf_op_layer_add_44[0][0]         \n",
            "                                                                 tf_op_layer_Square_22[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Exp_22 (TensorFlowO [(None, 2)]          0           dense_451[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_sub_67 (TensorFlowO [(None, 2)]          0           tf_op_layer_sub_66[0][0]         \n",
            "                                                                 tf_op_layer_Exp_22[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Sum_22 (TensorFlowO [(None,)]            0           tf_op_layer_sub_67[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_mul_67 (TensorFlowO [(None,)]            0           tf_op_layer_Sum_22[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_SquaredDifference_2 [(None, 4)]          0           model_67[0][0]                   \n",
            "                                                                 input_45[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_sub_68 (TensorFlowO [(None,)]            0           tf_op_layer_mul_67[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Mean_44 (TensorFlow [(None,)]            0           tf_op_layer_SquaredDifference_22[\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Abs_22 (TensorFlowO [(None,)]            0           tf_op_layer_sub_68[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_mul_66 (TensorFlowO [(None,)]            0           tf_op_layer_Mean_44[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_mul_68 (TensorFlowO [(None,)]            0           tf_op_layer_Abs_22[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_add_45 (TensorFlowO [(None,)]            0           tf_op_layer_mul_66[0][0]         \n",
            "                                                                 tf_op_layer_mul_68[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Mean_45 (TensorFlow [()]                 0           tf_op_layer_add_45[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "add_loss_22 (AddLoss)           ()                   0           tf_op_layer_Mean_45[0][0]        \n",
            "==================================================================================================\n",
            "Total params: 124\n",
            "Trainable params: 124\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1668 samples, validate on 186 samples\n",
            "Epoch 1/100\n",
            "1664/1668 [============================>.] - ETA: 0s - loss: 4.9392"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1668/1668 [==============================] - 8s 5ms/sample - loss: 4.9365 - val_loss: 4.5332\n",
            "Epoch 2/100\n",
            "1668/1668 [==============================] - 0s 133us/sample - loss: 4.6622 - val_loss: 4.2434\n",
            "Epoch 3/100\n",
            "1668/1668 [==============================] - 0s 133us/sample - loss: 4.3425 - val_loss: 3.8142\n",
            "Epoch 4/100\n",
            "1668/1668 [==============================] - 0s 135us/sample - loss: 4.0384 - val_loss: 3.4173\n",
            "Epoch 5/100\n",
            "1668/1668 [==============================] - 0s 137us/sample - loss: 3.7309 - val_loss: 3.1297\n",
            "Epoch 6/100\n",
            "1668/1668 [==============================] - 0s 133us/sample - loss: 3.5576 - val_loss: 2.9538\n",
            "Epoch 7/100\n",
            "1668/1668 [==============================] - 0s 134us/sample - loss: 3.4243 - val_loss: 2.8765\n",
            "Epoch 8/100\n",
            "1668/1668 [==============================] - 0s 134us/sample - loss: 3.3488 - val_loss: 2.8367\n",
            "Epoch 9/100\n",
            "1668/1668 [==============================] - 0s 134us/sample - loss: 3.3064 - val_loss: 2.8089\n",
            "Epoch 10/100\n",
            "1668/1668 [==============================] - 0s 135us/sample - loss: 3.2904 - val_loss: 2.7978\n",
            "Epoch 11/100\n",
            "1668/1668 [==============================] - 0s 137us/sample - loss: 3.2173 - val_loss: 2.7958\n",
            "Epoch 12/100\n",
            "1668/1668 [==============================] - 0s 140us/sample - loss: 3.1906 - val_loss: 2.7949\n",
            "Epoch 13/100\n",
            "1668/1668 [==============================] - 0s 130us/sample - loss: 3.1516 - val_loss: 2.7907\n",
            "Epoch 14/100\n",
            "1668/1668 [==============================] - 0s 132us/sample - loss: 3.1228 - val_loss: 2.7909\n",
            "Epoch 15/100\n",
            "1668/1668 [==============================] - 0s 132us/sample - loss: 3.1140 - val_loss: 2.7896\n",
            "Epoch 16/100\n",
            "1668/1668 [==============================] - 0s 132us/sample - loss: 3.0988 - val_loss: 2.7882\n",
            "Epoch 17/100\n",
            "1668/1668 [==============================] - 0s 132us/sample - loss: 3.0972 - val_loss: 2.7889\n",
            "Epoch 18/100\n",
            "1668/1668 [==============================] - 0s 127us/sample - loss: 3.0997 - val_loss: 2.7893\n",
            "Epoch 19/100\n",
            "1668/1668 [==============================] - 0s 134us/sample - loss: 3.0875 - val_loss: 2.7888\n",
            "Epoch 20/100\n",
            "1668/1668 [==============================] - 0s 138us/sample - loss: 3.0717 - val_loss: 2.7886\n",
            "Epoch 21/100\n",
            "1668/1668 [==============================] - 0s 134us/sample - loss: 3.0807 - val_loss: 2.7887\n",
            "Epoch 22/100\n",
            "1668/1668 [==============================] - 0s 133us/sample - loss: 3.0734 - val_loss: 2.7887\n",
            "Epoch 23/100\n",
            "1668/1668 [==============================] - 0s 134us/sample - loss: 3.0723 - val_loss: 2.7888\n",
            "Epoch 24/100\n",
            "1668/1668 [==============================] - 0s 133us/sample - loss: 3.0714 - val_loss: 2.7888\n",
            "Epoch 25/100\n",
            "1668/1668 [==============================] - 0s 129us/sample - loss: 3.0652 - val_loss: 2.7887\n",
            "Epoch 26/100\n",
            "1668/1668 [==============================] - 0s 131us/sample - loss: 3.0532 - val_loss: 2.7888\n",
            "Epoch 27/100\n",
            "1668/1668 [==============================] - 0s 132us/sample - loss: 3.0547 - val_loss: 2.7887\n",
            "Epoch 28/100\n",
            "1668/1668 [==============================] - 0s 133us/sample - loss: 3.0452 - val_loss: 2.7888\n",
            "Epoch 29/100\n",
            "1668/1668 [==============================] - 0s 135us/sample - loss: 3.0514 - val_loss: 2.7888\n",
            "Epoch 30/100\n",
            "1668/1668 [==============================] - 0s 130us/sample - loss: 3.0470 - val_loss: 2.7888\n",
            "Epoch 31/100\n",
            "1668/1668 [==============================] - 0s 130us/sample - loss: 3.0473 - val_loss: 2.7888\n",
            "Epoch 32/100\n",
            "1668/1668 [==============================] - 0s 132us/sample - loss: 3.0383 - val_loss: 2.7888\n",
            "Epoch 33/100\n",
            "1668/1668 [==============================] - 0s 131us/sample - loss: 3.0443 - val_loss: 2.7888\n",
            "Epoch 34/100\n",
            "1668/1668 [==============================] - 0s 128us/sample - loss: 3.0433 - val_loss: 2.7888\n",
            "Epoch 35/100\n",
            "1668/1668 [==============================] - 0s 130us/sample - loss: 3.0476 - val_loss: 2.7888\n",
            "Epoch 36/100\n",
            "1668/1668 [==============================] - 0s 130us/sample - loss: 3.0429 - val_loss: 2.7888\n",
            "Epoch 37/100\n",
            "1668/1668 [==============================] - 0s 134us/sample - loss: 3.0432 - val_loss: 2.7888\n",
            "Epoch 38/100\n",
            "1668/1668 [==============================] - 0s 133us/sample - loss: 3.0420 - val_loss: 2.7888\n",
            "Epoch 39/100\n",
            "1668/1668 [==============================] - 0s 129us/sample - loss: 3.0497 - val_loss: 2.7888\n",
            "Epoch 40/100\n",
            "1668/1668 [==============================] - 0s 132us/sample - loss: 3.0443 - val_loss: 2.7888\n",
            "Epoch 41/100\n",
            "1668/1668 [==============================] - 0s 130us/sample - loss: 3.0370 - val_loss: 2.7888\n",
            "Epoch 42/100\n",
            "1668/1668 [==============================] - 0s 134us/sample - loss: 3.0415 - val_loss: 2.7888\n",
            "Epoch 43/100\n",
            "1668/1668 [==============================] - 0s 132us/sample - loss: 3.0405 - val_loss: 2.7888\n",
            "Epoch 44/100\n",
            "1668/1668 [==============================] - 0s 131us/sample - loss: 3.0356 - val_loss: 2.7888\n",
            "Epoch 45/100\n",
            "1668/1668 [==============================] - 0s 129us/sample - loss: 3.0358 - val_loss: 2.7888\n",
            "Epoch 46/100\n",
            "1668/1668 [==============================] - 0s 133us/sample - loss: 3.0346 - val_loss: 2.7888\n",
            "Epoch 47/100\n",
            "1668/1668 [==============================] - 0s 132us/sample - loss: 3.0362 - val_loss: 2.7888\n",
            "Epoch 48/100\n",
            "1668/1668 [==============================] - 0s 132us/sample - loss: 3.0402 - val_loss: 2.7888\n",
            "Epoch 49/100\n",
            "1668/1668 [==============================] - 0s 131us/sample - loss: 3.0391 - val_loss: 2.7888\n",
            "Epoch 50/100\n",
            "1668/1668 [==============================] - 0s 129us/sample - loss: 3.0502 - val_loss: 2.7888\n",
            "Epoch 51/100\n",
            "1668/1668 [==============================] - 0s 130us/sample - loss: 3.0408 - val_loss: 2.7888\n",
            "Epoch 52/100\n",
            "1668/1668 [==============================] - 0s 129us/sample - loss: 3.0420 - val_loss: 2.7888\n",
            "Epoch 53/100\n",
            "1668/1668 [==============================] - 0s 129us/sample - loss: 3.0424 - val_loss: 2.7888\n",
            "Epoch 54/100\n",
            "1668/1668 [==============================] - 0s 129us/sample - loss: 3.0339 - val_loss: 2.7888\n",
            "Epoch 55/100\n",
            "1668/1668 [==============================] - 0s 129us/sample - loss: 3.0340 - val_loss: 2.7888\n",
            "Epoch 56/100\n",
            "1668/1668 [==============================] - 0s 127us/sample - loss: 3.0316 - val_loss: 2.7888\n",
            "Epoch 57/100\n",
            "1668/1668 [==============================] - 0s 128us/sample - loss: 3.0346 - val_loss: 2.7888\n",
            "Epoch 58/100\n",
            "1668/1668 [==============================] - 0s 128us/sample - loss: 3.0393 - val_loss: 2.7888\n",
            "Epoch 59/100\n",
            "1668/1668 [==============================] - 0s 129us/sample - loss: 3.0327 - val_loss: 2.7888\n",
            "Epoch 60/100\n",
            "1668/1668 [==============================] - 0s 134us/sample - loss: 3.0387 - val_loss: 2.7888\n",
            "Epoch 61/100\n",
            "1668/1668 [==============================] - 0s 134us/sample - loss: 3.0344 - val_loss: 2.7888\n",
            "Epoch 62/100\n",
            "1668/1668 [==============================] - 0s 129us/sample - loss: 3.0325 - val_loss: 2.7888\n",
            "Epoch 63/100\n",
            "1668/1668 [==============================] - 0s 128us/sample - loss: 3.0301 - val_loss: 2.7888\n",
            "Epoch 64/100\n",
            "1668/1668 [==============================] - 0s 130us/sample - loss: 3.0343 - val_loss: 2.7888\n",
            "Epoch 65/100\n",
            "1668/1668 [==============================] - 0s 130us/sample - loss: 3.0333 - val_loss: 2.7888\n",
            "Epoch 66/100\n",
            "1668/1668 [==============================] - 0s 132us/sample - loss: 3.0328 - val_loss: 2.7888\n",
            "Epoch 67/100\n",
            "1668/1668 [==============================] - 0s 136us/sample - loss: 3.0290 - val_loss: 2.7888\n",
            "Epoch 68/100\n",
            "1668/1668 [==============================] - 0s 131us/sample - loss: 3.0305 - val_loss: 2.7888\n",
            "Epoch 69/100\n",
            "1668/1668 [==============================] - 0s 133us/sample - loss: 3.0323 - val_loss: 2.7888\n",
            "Epoch 70/100\n",
            "1668/1668 [==============================] - 0s 132us/sample - loss: 3.0363 - val_loss: 2.7888\n",
            "Epoch 71/100\n",
            "1668/1668 [==============================] - 0s 131us/sample - loss: 3.0360 - val_loss: 2.7888\n",
            "Epoch 72/100\n",
            "1668/1668 [==============================] - 0s 130us/sample - loss: 3.0315 - val_loss: 2.7888\n",
            "Epoch 73/100\n",
            "1668/1668 [==============================] - 0s 132us/sample - loss: 3.0305 - val_loss: 2.7888\n",
            "Epoch 74/100\n",
            "1668/1668 [==============================] - 0s 133us/sample - loss: 3.0337 - val_loss: 2.7888\n",
            "Epoch 75/100\n",
            "1668/1668 [==============================] - 0s 132us/sample - loss: 3.0281 - val_loss: 2.7888\n",
            "Epoch 76/100\n",
            "1668/1668 [==============================] - 0s 132us/sample - loss: 3.0299 - val_loss: 2.7888\n",
            "Epoch 77/100\n",
            "1668/1668 [==============================] - 0s 132us/sample - loss: 3.0293 - val_loss: 2.7888\n",
            "Epoch 78/100\n",
            "1668/1668 [==============================] - 0s 132us/sample - loss: 3.0295 - val_loss: 2.7888\n",
            "Epoch 79/100\n",
            "1668/1668 [==============================] - 0s 134us/sample - loss: 3.0274 - val_loss: 2.7888\n",
            "Epoch 80/100\n",
            "1668/1668 [==============================] - 0s 131us/sample - loss: 3.0273 - val_loss: 2.7888\n",
            "Epoch 81/100\n",
            "1668/1668 [==============================] - 0s 131us/sample - loss: 3.0282 - val_loss: 2.7888\n",
            "Epoch 82/100\n",
            "1668/1668 [==============================] - 0s 132us/sample - loss: 3.0266 - val_loss: 2.7888\n",
            "Epoch 83/100\n",
            "1668/1668 [==============================] - 0s 134us/sample - loss: 3.0276 - val_loss: 2.7888\n",
            "Epoch 84/100\n",
            "1668/1668 [==============================] - 0s 134us/sample - loss: 3.0287 - val_loss: 2.7888\n",
            "Epoch 85/100\n",
            "1668/1668 [==============================] - 0s 131us/sample - loss: 3.0269 - val_loss: 2.7888\n",
            "Epoch 86/100\n",
            "1668/1668 [==============================] - 0s 130us/sample - loss: 3.0282 - val_loss: 2.7888\n",
            "Epoch 87/100\n",
            "1668/1668 [==============================] - 0s 133us/sample - loss: 3.0296 - val_loss: 2.7888\n",
            "Epoch 88/100\n",
            "1668/1668 [==============================] - 0s 132us/sample - loss: 3.0280 - val_loss: 2.7888\n",
            "Epoch 89/100\n",
            "1668/1668 [==============================] - 0s 131us/sample - loss: 3.0270 - val_loss: 2.7888\n",
            "Epoch 90/100\n",
            "1668/1668 [==============================] - 0s 132us/sample - loss: 3.0247 - val_loss: 2.7888\n",
            "Epoch 91/100\n",
            "1668/1668 [==============================] - 0s 131us/sample - loss: 3.0288 - val_loss: 2.7888\n",
            "Epoch 92/100\n",
            "1668/1668 [==============================] - 0s 133us/sample - loss: 3.0287 - val_loss: 2.7888\n",
            "Epoch 93/100\n",
            "1668/1668 [==============================] - 0s 132us/sample - loss: 3.0299 - val_loss: 2.7888\n",
            "Epoch 94/100\n",
            "1668/1668 [==============================] - 0s 131us/sample - loss: 3.0291 - val_loss: 2.7888\n",
            "Epoch 95/100\n",
            "1668/1668 [==============================] - 0s 130us/sample - loss: 3.0281 - val_loss: 2.7888\n",
            "Epoch 96/100\n",
            "1668/1668 [==============================] - 0s 132us/sample - loss: 3.0264 - val_loss: 2.7888\n",
            "Epoch 97/100\n",
            "1668/1668 [==============================] - 0s 132us/sample - loss: 3.0285 - val_loss: 2.7888\n",
            "Epoch 98/100\n",
            "1668/1668 [==============================] - 0s 131us/sample - loss: 3.0263 - val_loss: 2.7888\n",
            "Epoch 99/100\n",
            "1668/1668 [==============================] - 0s 131us/sample - loss: 3.0286 - val_loss: 2.7888\n",
            "Epoch 100/100\n",
            "1668/1668 [==============================] - 0s 132us/sample - loss: 3.0239 - val_loss: 2.7888\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
            "  warnings.warn(\"Numerical issues were encountered \"\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/src/tods/tods/searcher/brute_force_search.py\", line 62, in _search\n",
            "    for error in pipeline_result.error:\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
            "  warnings.warn(\"Numerical issues were encountered \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_34\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_457 (Dense)            (None, 4)                 20        \n",
            "_________________________________________________________________\n",
            "dropout_308 (Dropout)        (None, 4)                 0         \n",
            "_________________________________________________________________\n",
            "dense_458 (Dense)            (None, 4)                 20        \n",
            "_________________________________________________________________\n",
            "dropout_309 (Dropout)        (None, 4)                 0         \n",
            "_________________________________________________________________\n",
            "dense_459 (Dense)            (None, 1)                 5         \n",
            "_________________________________________________________________\n",
            "dropout_310 (Dropout)        (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "dense_460 (Dense)            (None, 4)                 8         \n",
            "_________________________________________________________________\n",
            "dropout_311 (Dropout)        (None, 4)                 0         \n",
            "_________________________________________________________________\n",
            "dense_461 (Dense)            (None, 1)                 5         \n",
            "_________________________________________________________________\n",
            "dropout_312 (Dropout)        (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "dense_462 (Dense)            (None, 4)                 8         \n",
            "=================================================================\n",
            "Total params: 66\n",
            "Trainable params: 66\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 1668 samples, validate on 186 samples\n",
            "Epoch 1/20\n",
            "1376/1668 [=======================>......] - ETA: 1s - loss: 1.7178"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1668/1668 [==============================] - 8s 5ms/sample - loss: 1.6452 - val_loss: 1.3010\n",
            "Epoch 2/20\n",
            "1668/1668 [==============================] - 0s 123us/sample - loss: 1.5095 - val_loss: 1.2410\n",
            "Epoch 3/20\n",
            "1668/1668 [==============================] - 0s 122us/sample - loss: 1.4375 - val_loss: 1.1975\n",
            "Epoch 4/20\n",
            "1668/1668 [==============================] - 0s 122us/sample - loss: 1.3818 - val_loss: 1.1608\n",
            "Epoch 5/20\n",
            "1668/1668 [==============================] - 0s 120us/sample - loss: 1.3387 - val_loss: 1.1288\n",
            "Epoch 6/20\n",
            "1668/1668 [==============================] - 0s 119us/sample - loss: 1.3025 - val_loss: 1.1001\n",
            "Epoch 7/20\n",
            "1668/1668 [==============================] - 0s 121us/sample - loss: 1.2682 - val_loss: 1.0743\n",
            "Epoch 8/20\n",
            "1668/1668 [==============================] - 0s 120us/sample - loss: 1.2386 - val_loss: 1.0508\n",
            "Epoch 9/20\n",
            "1668/1668 [==============================] - 0s 122us/sample - loss: 1.2117 - val_loss: 1.0293\n",
            "Epoch 10/20\n",
            "1668/1668 [==============================] - 0s 122us/sample - loss: 1.1893 - val_loss: 1.0094\n",
            "Epoch 11/20\n",
            "1668/1668 [==============================] - 0s 119us/sample - loss: 1.1675 - val_loss: 0.9908\n",
            "Epoch 12/20\n",
            "1668/1668 [==============================] - 0s 123us/sample - loss: 1.1489 - val_loss: 0.9736\n",
            "Epoch 13/20\n",
            "1668/1668 [==============================] - 0s 119us/sample - loss: 1.1284 - val_loss: 0.9574\n",
            "Epoch 14/20\n",
            "1668/1668 [==============================] - 0s 119us/sample - loss: 1.1111 - val_loss: 0.9422\n",
            "Epoch 15/20\n",
            "1668/1668 [==============================] - 0s 120us/sample - loss: 1.0949 - val_loss: 0.9278\n",
            "Epoch 16/20\n",
            "1668/1668 [==============================] - 0s 119us/sample - loss: 1.0807 - val_loss: 0.9144\n",
            "Epoch 17/20\n",
            "1668/1668 [==============================] - 0s 120us/sample - loss: 1.0668 - val_loss: 0.9017\n",
            "Epoch 18/20\n",
            "1668/1668 [==============================] - 0s 120us/sample - loss: 1.0532 - val_loss: 0.8898\n",
            "Epoch 19/20\n",
            "1668/1668 [==============================] - 0s 119us/sample - loss: 1.0406 - val_loss: 0.8785\n",
            "Epoch 20/20\n",
            "1668/1668 [==============================] - 0s 121us/sample - loss: 1.0291 - val_loss: 0.8676\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n",
            "Not all provided hyper-parameters for the data preparation pipeline 79ce71bd-db96-494b-a455-14f2e2ac5040 were used: ['method', 'number_of_folds', 'randomSeed', 'shuffle', 'stratified']\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
            "  warnings.warn(\"Numerical issues were encountered \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_35\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_463 (Dense)            (None, 4)                 20        \n",
            "_________________________________________________________________\n",
            "dropout_313 (Dropout)        (None, 4)                 0         \n",
            "_________________________________________________________________\n",
            "dense_464 (Dense)            (None, 4)                 20        \n",
            "_________________________________________________________________\n",
            "dropout_314 (Dropout)        (None, 4)                 0         \n",
            "_________________________________________________________________\n",
            "dense_465 (Dense)            (None, 1)                 5         \n",
            "_________________________________________________________________\n",
            "dropout_315 (Dropout)        (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "dense_466 (Dense)            (None, 4)                 8         \n",
            "_________________________________________________________________\n",
            "dropout_316 (Dropout)        (None, 4)                 0         \n",
            "_________________________________________________________________\n",
            "dense_467 (Dense)            (None, 1)                 5         \n",
            "_________________________________________________________________\n",
            "dropout_317 (Dropout)        (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "dense_468 (Dense)            (None, 4)                 8         \n",
            "=================================================================\n",
            "Total params: 66\n",
            "Trainable params: 66\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 1668 samples, validate on 186 samples\n",
            "Epoch 1/20\n",
            "1472/1668 [=========================>....] - ETA: 0s - loss: 1.4469"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1668/1668 [==============================] - 8s 5ms/sample - loss: 1.4093 - val_loss: 1.1816\n",
            "Epoch 2/20\n",
            "1668/1668 [==============================] - 0s 121us/sample - loss: 1.3729 - val_loss: 1.1540\n",
            "Epoch 3/20\n",
            "1668/1668 [==============================] - 0s 121us/sample - loss: 1.3419 - val_loss: 1.1288\n",
            "Epoch 4/20\n",
            "1668/1668 [==============================] - 0s 118us/sample - loss: 1.3131 - val_loss: 1.1054\n",
            "Epoch 5/20\n",
            "1668/1668 [==============================] - 0s 118us/sample - loss: 1.2865 - val_loss: 1.0833\n",
            "Epoch 6/20\n",
            "1668/1668 [==============================] - 0s 118us/sample - loss: 1.2637 - val_loss: 1.0621\n",
            "Epoch 7/20\n",
            "1668/1668 [==============================] - 0s 124us/sample - loss: 1.2396 - val_loss: 1.0421\n",
            "Epoch 8/20\n",
            "1668/1668 [==============================] - 0s 122us/sample - loss: 1.2168 - val_loss: 1.0231\n",
            "Epoch 9/20\n",
            "1668/1668 [==============================] - 0s 122us/sample - loss: 1.1968 - val_loss: 1.0051\n",
            "Epoch 10/20\n",
            "1668/1668 [==============================] - 0s 123us/sample - loss: 1.1766 - val_loss: 0.9879\n",
            "Epoch 11/20\n",
            "1668/1668 [==============================] - 0s 120us/sample - loss: 1.1579 - val_loss: 0.9715\n",
            "Epoch 12/20\n",
            "1668/1668 [==============================] - 0s 123us/sample - loss: 1.1407 - val_loss: 0.9558\n",
            "Epoch 13/20\n",
            "1668/1668 [==============================] - 0s 122us/sample - loss: 1.1238 - val_loss: 0.9409\n",
            "Epoch 14/20\n",
            "1668/1668 [==============================] - 0s 119us/sample - loss: 1.1080 - val_loss: 0.9268\n",
            "Epoch 15/20\n",
            "1668/1668 [==============================] - 0s 120us/sample - loss: 1.0931 - val_loss: 0.9133\n",
            "Epoch 16/20\n",
            "1668/1668 [==============================] - 0s 119us/sample - loss: 1.0788 - val_loss: 0.9004\n",
            "Epoch 17/20\n",
            "1668/1668 [==============================] - 0s 123us/sample - loss: 1.0650 - val_loss: 0.8882\n",
            "Epoch 18/20\n",
            "1668/1668 [==============================] - 0s 121us/sample - loss: 1.0525 - val_loss: 0.8766\n",
            "Epoch 19/20\n",
            "1668/1668 [==============================] - 0s 116us/sample - loss: 1.0403 - val_loss: 0.8658\n",
            "Epoch 20/20\n",
            "1668/1668 [==============================] - 0s 117us/sample - loss: 1.0289 - val_loss: 0.8554\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
            "  warnings.warn(\"Numerical issues were encountered \"\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "from axolotl.backend.simple import SimpleRunner\n",
        "\n",
        "from tods import generate_dataset, generate_problem\n",
        "from tods.searcher import BruteForceSearch\n",
        "\n",
        "# Some information\n",
        "#table_path = 'datasets/yahoo_sub_5.csv'\n",
        "target_index = 2 # what column is the target\n",
        "time_limit = 300 # How many seconds you wanna search\n",
        "metric = 'F1_MACRO' # F1 on both label 0 and 1\n",
        "\n",
        "# Read data and generate dataset and problem\n",
        "#df = pd.read_csv(table_path)\n",
        "dataset = generate_dataset(group2, target_index=target_index)\n",
        "problem_description = generate_problem(dataset, metric)\n",
        "\n",
        "# Start backend\n",
        "backend = SimpleRunner(random_seed=0)\n",
        "\n",
        "# Start search algorithm\n",
        "search = BruteForceSearch(problem_description=problem_description,\n",
        "                          backend=backend)\n",
        "\n",
        "# Find the best pipeline\n",
        "best_runtime, best_pipeline_result = search.search_fit(input_data=[dataset], time_limit=time_limit)\n",
        "best_pipeline = best_runtime.pipeline\n",
        "best_output = best_pipeline_result.output\n",
        "\n",
        "# Evaluate the best pipeline\n",
        "best_scores = search.evaluate(best_pipeline).scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4DfvbLSY9ni",
        "outputId": "122f9570-f7b8-4c89-8297-97d06b7c6aee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Search History:\n",
            "----------------------------------------------------\n",
            "Pipeline id: 702fc6d7-e01c-4986-bde4-081ca1554138\n",
            "     metric     value  normalized  randomSeed  fold\n",
            "0  F1_MACRO  0.592933    0.592933           0     0\n",
            "----------------------------------------------------\n",
            "Pipeline id: 3b7664a4-162c-4118-a97e-39c576135187\n",
            "     metric     value  normalized  randomSeed  fold\n",
            "0  F1_MACRO  0.545093    0.545093           0     0\n",
            "----------------------------------------------------\n",
            "Pipeline id: 80321adf-9b87-4a71-9675-784c7d9d3958\n",
            "     metric     value  normalized  randomSeed  fold\n",
            "0  F1_MACRO  0.508459    0.508459           0     0\n",
            "----------------------------------------------------\n",
            "Pipeline id: b77223ff-1d29-49ee-998a-5512f7d50654\n",
            "     metric     value  normalized  randomSeed  fold\n",
            "0  F1_MACRO  0.497254    0.497254           0     0\n",
            "----------------------------------------------------\n",
            "Pipeline id: d1c4036e-c7df-462f-827b-479a64726d9a\n",
            "     metric     value  normalized  randomSeed  fold\n",
            "0  F1_MACRO  0.484502    0.484502           0     0\n",
            "----------------------------------------------------\n",
            "Pipeline id: ace4e203-3575-40f1-a3b2-1d741515f709\n",
            "     metric     value  normalized  randomSeed  fold\n",
            "0  F1_MACRO  0.466886    0.466886           0     0\n",
            "----------------------------------------------------\n",
            "Pipeline id: 55d8077a-5ba9-4bb9-9281-fc998890d9ca\n",
            "     metric    value  normalized  randomSeed  fold\n",
            "0  F1_MACRO  0.45004     0.45004           0     0\n",
            "----------------------------------------------------\n",
            "Pipeline id: 5f8ddc95-3b98-4f6a-a2ad-ae8d56bf8495\n",
            "     metric     value  normalized  randomSeed  fold\n",
            "0  F1_MACRO  0.592933    0.592933           0     0\n",
            "----------------------------------------------------\n",
            "Pipeline id: ae03bc2f-6353-4800-9124-06ced8d49b55\n",
            "     metric     value  normalized  randomSeed  fold\n",
            "0  F1_MACRO  0.545093    0.545093           0     0\n",
            "----------------------------------------------------\n",
            "Pipeline id: b760a5f1-e805-45e9-aefa-4f64112c6042\n",
            "     metric     value  normalized  randomSeed  fold\n",
            "0  F1_MACRO  0.508459    0.508459           0     0\n"
          ]
        }
      ],
      "source": [
        "print('Search History:')\n",
        "for pipeline_result in search.history:\n",
        "    print('-' * 52)\n",
        "    print('Pipeline id:', pipeline_result.pipeline.id)\n",
        "    print(pipeline_result.scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yA-PmYPskVXE",
        "outputId": "20edbb0b-74d9-493a-d9fc-d048c0ca316f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best pipeline:\n",
            "----------------------------------------------------\n",
            "Pipeline id: 702fc6d7-e01c-4986-bde4-081ca1554138\n",
            "Pipeline json: {\"id\": \"702fc6d7-e01c-4986-bde4-081ca1554138\", \"schema\": \"https://metadata.datadrivendiscovery.org/schemas/v0/pipeline.json\", \"created\": \"2022-06-15T13:58:24.250205Z\", \"inputs\": [{\"name\": \"inputs\"}], \"outputs\": [{\"data\": \"steps.7.produce\", \"name\": \"output predictions\"}], \"steps\": [{\"type\": \"PRIMITIVE\", \"primitive\": {\"id\": \"c78138d9-9377-31dc-aee8-83d9df049c60\", \"version\": \"0.3.0\", \"python_path\": \"d3m.primitives.tods.data_processing.dataset_to_dataframe\", \"name\": \"Extract a DataFrame from a Dataset\"}, \"arguments\": {\"inputs\": {\"type\": \"CONTAINER\", \"data\": \"inputs.0\"}}, \"outputs\": [{\"id\": \"produce\"}]}, {\"type\": \"PRIMITIVE\", \"primitive\": {\"id\": \"81235c29-aeb9-3828-911a-1b25319b6998\", \"version\": \"0.6.0\", \"python_path\": \"d3m.primitives.tods.data_processing.column_parser\", \"name\": \"Parses strings into their types\"}, \"arguments\": {\"inputs\": {\"type\": \"CONTAINER\", \"data\": \"steps.0.produce\"}}, \"outputs\": [{\"id\": \"produce\"}]}, {\"type\": \"PRIMITIVE\", \"primitive\": {\"id\": \"a996cd89-ddf0-367f-8e7f-8c013cbc2891\", \"version\": \"0.4.0\", \"python_path\": \"d3m.primitives.tods.data_processing.extract_columns_by_semantic_types\", \"name\": \"Extracts columns by semantic type\"}, \"arguments\": {\"inputs\": {\"type\": \"CONTAINER\", \"data\": \"steps.1.produce\"}}, \"outputs\": [{\"id\": \"produce\"}], \"hyperparams\": {\"semantic_types\": {\"type\": \"VALUE\", \"data\": [\"https://metadata.datadrivendiscovery.org/types/Attribute\"]}}}, {\"type\": \"PRIMITIVE\", \"primitive\": {\"id\": \"a996cd89-ddf0-367f-8e7f-8c013cbc2891\", \"version\": \"0.4.0\", \"python_path\": \"d3m.primitives.tods.data_processing.extract_columns_by_semantic_types\", \"name\": \"Extracts columns by semantic type\"}, \"arguments\": {\"inputs\": {\"type\": \"CONTAINER\", \"data\": \"steps.0.produce\"}}, \"outputs\": [{\"id\": \"produce\"}], \"hyperparams\": {\"semantic_types\": {\"type\": \"VALUE\", \"data\": [\"https://metadata.datadrivendiscovery.org/types/TrueTarget\"]}}}, {\"type\": \"PRIMITIVE\", \"primitive\": {\"id\": \"642de2e7-5590-3cab-9266-2a53c326c461\", \"version\": \"0.0.1\", \"python_path\": \"d3m.primitives.tods.timeseries_processing.transformation.axiswise_scaler\", \"name\": \"Axis_wise_scale\"}, \"arguments\": {\"inputs\": {\"type\": \"CONTAINER\", \"data\": \"steps.2.produce\"}}, \"outputs\": [{\"id\": \"produce\"}]}, {\"type\": \"PRIMITIVE\", \"primitive\": {\"id\": \"30bc7cec-2ccc-34bc-9df8-2095bf3b1ae2\", \"version\": \"0.1.0\", \"python_path\": \"d3m.primitives.tods.feature_analysis.statistical_mean\", \"name\": \"Time Series Decompostional\"}, \"arguments\": {\"inputs\": {\"type\": \"CONTAINER\", \"data\": \"steps.4.produce\"}}, \"outputs\": [{\"id\": \"produce\"}]}, {\"type\": \"PRIMITIVE\", \"primitive\": {\"id\": \"67e7fcdf-d645-3417-9aa4-85cd369487d9\", \"version\": \"0.0.1\", \"python_path\": \"d3m.primitives.tods.detection_algorithm.pyod_ae\", \"name\": \"TODS.anomaly_detection_primitives.AutoEncoder\"}, \"arguments\": {\"inputs\": {\"type\": \"CONTAINER\", \"data\": \"steps.5.produce\"}}, \"outputs\": [{\"id\": \"produce\"}], \"hyperparams\": {\"contamination\": {\"type\": \"VALUE\", \"data\": 0.01}}}, {\"type\": \"PRIMITIVE\", \"primitive\": {\"id\": \"2530840a-07d4-3874-b7d8-9eb5e4ae2bf3\", \"version\": \"0.3.0\", \"python_path\": \"d3m.primitives.tods.data_processing.construct_predictions\", \"name\": \"Construct pipeline predictions output\"}, \"arguments\": {\"inputs\": {\"type\": \"CONTAINER\", \"data\": \"steps.6.produce\"}, \"reference\": {\"type\": \"CONTAINER\", \"data\": \"steps.1.produce\"}}, \"outputs\": [{\"id\": \"produce\"}]}], \"digest\": \"09bb405c9cb2869a2112a1bff5547d9a47e438775a3b4fb46300a2e035c11128\"}\n",
            "Output:\n",
            "     d3mIndex  label\n",
            "0           0      0\n",
            "1           1      0\n",
            "2           2      0\n",
            "3           3      0\n",
            "4           4      0\n",
            "...       ...    ...\n",
            "1849     1849      0\n",
            "1850     1850      0\n",
            "1851     1851      0\n",
            "1852     1852      0\n",
            "1853     1853      0\n",
            "\n",
            "[1854 rows x 2 columns]\n",
            "Scores:\n",
            "     metric     value  normalized  randomSeed  fold\n",
            "0  F1_MACRO  0.592933    0.592933           0     0\n"
          ]
        }
      ],
      "source": [
        "print('Best pipeline:')\n",
        "print('-' * 52)\n",
        "print('Pipeline id:', best_pipeline.id)\n",
        "print('Pipeline json:', best_pipeline.to_json())\n",
        "print('Output:')\n",
        "print(best_output)\n",
        "print('Scores:')\n",
        "print(best_scores)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}